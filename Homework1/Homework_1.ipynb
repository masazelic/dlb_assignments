{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GGZawn6zjw8B"
   },
   "source": [
    "# Homework 1 - Marija Zelic, 371272\n",
    "\n",
    "In this homework, we're going to build a neural network without using deep learning packages.\n",
    "\n",
    "Specifically, we're going to build a neural network that annotate cells to cell types in the Pancreas tissue. To do so, we'll need a few building blocks:\n",
    "- Fully-connected layer, $f(X)=X \\cdot W + \\vec{b}$\n",
    "- Nonlinearity layer (ReLU in this homework)\n",
    "- Loss function (Cross-entropy in this homework)\n",
    "- Backprop algorithm - a stochastic gradient descent with backpropageted gradients\n",
    "\n",
    "Reference: \n",
    "- https://github.com/yandexdataschool/Practical_DL/tree/fall23\n",
    "- https://github.com/theislab/scarches-reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U_M_6S9Ujw8C",
    "outputId": "173ca758-099b-4fc0-9056-dd5717d38034",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jF1dyLBTjw8D"
   },
   "source": [
    "## 0. Create the Parent Class 'Layer' (0 pt)\n",
    "\n",
    "As we learned in the lecture, we need layers that can do both forward pass and backward pass. Here we define the parent class of all layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "fQv1zgRUjw8D",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Layer:\n",
    "\n",
    "    \"\"\"\n",
    "    Each layer performs two things:\n",
    "    1. Forward pass: Process input to get output: output = layer.forward(input)\n",
    "    2. Backward pass: Back-propagate gradients through itself: grad_input = layer.backward(input, grad_output)\n",
    "\n",
    "    The layers that contain learnable parameters also update their parameters during layer.backward.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize layer parameters.\n",
    "        \"\"\"\n",
    "\n",
    "        # Here we use a dummy layer that does nothing.\n",
    "        pass\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        Takes input data of shape [batch, input_dims], returns output data [batch, output_dims]\n",
    "        \"\"\"\n",
    "\n",
    "        # Here we use a dummy layer that returns the input.\n",
    "        return input\n",
    "\n",
    "    def backward(self, input, grad_output):\n",
    "        \"\"\"\n",
    "        Performs a backpropagation step through the layer.\n",
    "\n",
    "        We need to apply the chain rule to compute the gradients of the input x:\n",
    "        d loss / d x  = (d loss / d layer) * (d layer / d x)\n",
    "\n",
    "        Grad_output provides us d loss / d layer, so we only need to multiply it by d layer / d x.\n",
    "\n",
    "        Note that if the layer has trainable parameters, we also need to update them using d loss / d layer.\n",
    "        \"\"\"\n",
    "\n",
    "        # The gradient of a dummy layer is grad_output\n",
    "        return grad_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U3Q_CChKjw8E"
   },
   "source": [
    "## 1. Build layers\n",
    "\n",
    "We will shortly introduce our dataset's structure in this section, and it should be enough to complete the functions in this section. However, if you find knowing the dataset structure is super helpful to implement the functions of this section, *you can jump to Section 2* and check the dataset structure before going through this section.\n",
    "\n",
    "### 1.1. Nonlinearity layer - ReLU (1 pt) \n",
    "\n",
    "We start from the simplest layer: nonlinearity layer. It simply applies a nonlinearity to each element of your network and it contains no trainable parameter.\n",
    "\n",
    "Here we implement ReLU. \n",
    "\n",
    "Check this link to review ReLU if needed: https://www.v7labs.com/blog/neural-networks-activation-functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Sj5NNWB9jw8E",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ReLU(Layer):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        ReLU layer applies elementwise rectified linear to the elements in the inputs.\n",
    "        There is nothing to initialize in this simple implementation.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        Apply elementwise ReLU to the input\n",
    "        \"\"\"\n",
    "        output = np.maximum(0, input)\n",
    "        \n",
    "        return output\n",
    "\n",
    "    def backward(self, input, grad_output):\n",
    "        \"\"\"\n",
    "        Compute the gradient of loss. \n",
    "        grad_input = d loss / d x\n",
    "        grad_output = d loss / d y\n",
    "        \"\"\"\n",
    "        grad_input = grad_output.copy()\n",
    "        grad_input[input <= 0] = 0\n",
    "\n",
    "        return grad_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aihMC0K8jw8E"
   },
   "source": [
    "### 1.2. Fully-connected Layer (2 pts)\n",
    "\n",
    "After implementing the simplest layer, we come to a more complicated one: a fully-connected layer. Unlike a nonlinearity layer, a fully-connected layer has trainable parameters.\n",
    "\n",
    "A fully-connected layer applies an affine transformation. It can be described as: \n",
    "$$f(X)= X \\cdot W + \\vec b ,$$\n",
    "\n",
    "where\n",
    "* X is the input of shape [batch_size, input_dims],\n",
    "* W is a weight matrix [input_dims, output_dims],\n",
    "* and b is a vector of outputs_dims biases.\n",
    "\n",
    "W and b are\n",
    "* initialized when the layer is created,\n",
    "* and updated each time backward is called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "VOkSrmYzjw8E",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Fully_connected(Layer):\n",
    "    def __init__(self, input_dims, output_dims, learning_rate=0.1):\n",
    "        \"\"\"\n",
    "        Fully_connected layer: f(x) = <x*W> + b\n",
    "        We initialize W, b, and learning rate to update W and b.\n",
    "        input_dims = number of input neurons\n",
    "        output_dims = number of output neurons\n",
    "        \"\"\"\n",
    "        self.weights = 0.01 * np.random.randn(input_dims, output_dims)\n",
    "        self.biases = np.zeros((1, output_dims))\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def forward(self,input):\n",
    "        \"\"\"\n",
    "        Perform f(x) = <x*W> + b .\n",
    "        input shape: [batch, input_dims]\n",
    "        output shape: [batch, output_dims]\n",
    "        \"\"\"\n",
    "        output = np.dot(input, self.weights) + self.biases\n",
    "        \n",
    "        return output\n",
    "\n",
    "    def backward(self,input,grad_output):\n",
    "        \"\"\"\n",
    "        grad_input is defined as d loss / d x\n",
    "        grad_output is defined as d loss / d y (y is an output of the layer)\n",
    "        d loss / d B is the same as d loss / d y\n",
    "        \"\"\"\n",
    "        grad_input = np.dot(grad_output, self.weights.T)\n",
    "        grad_weights = np.dot(input.T, grad_output)\n",
    "        grad_biases = np.sum(grad_output, axis=0, keepdims=True)\n",
    "\n",
    "        # Here we perform a stochastic gradient descent (SGD) step: x = x - learning_rate * gradient_of_x.\n",
    "\n",
    "        self.weights = self.weights - self.learning_rate * grad_weights\n",
    "        self.biases = self.biases - self.learning_rate * grad_biases\n",
    "\n",
    "        return grad_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pvXCRmwKjw8G"
   },
   "source": [
    "### 1.3. The loss function - softmax cross-entropy (2 pts)\n",
    "\n",
    "Our model outputs the logits. Since we want to predict probabilities, it would be logical for us to apply softmax nonlinearity to our output logits and compute loss with predicted probabilities.\n",
    "\n",
    "If you are not familiar with softmax or cross-entropy loss, you can check:\n",
    "- Softmax: https://en.wikipedia.org/wiki/Softmax_function\n",
    "- Cross-entropy loss: https://ml-cheatsheet.readthedocs.io/en/latest/loss_functions.html#cross-entropy\n",
    "\n",
    "\n",
    "(We encourage you to first write down the expression for cross-entropy as a function of softmax logits. You can then try to rewrite it into a more concise form.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "jPw8k28mjw8G",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def softmax_crossentropy_with_logits(logits,reference_answers):\n",
    "    \"\"\"\n",
    "    Compute cross-entropy loss for each sample from output logits [batch,n_classes] and reference_answers [batch].\n",
    "    Note that the reference_answers are not one-hot labels. Instead, they are the index of the categories, e.g., 2 instead of [0,0,1].\n",
    "    The output (xentropy) shape should be [batch,1] or [batch].\n",
    "    \"\"\"\n",
    "    norm = np.exp(logits - np.max(logits, axis=1, keepdims=True))\n",
    "    softmax = norm / np.sum(norm, axis=1, keepdims = True)\n",
    "    softmax_clipped = np.clip(softmax, 1e-7, 1 - 1e-7)\n",
    "    xentropy = -np.log(softmax_clipped[range(len(softmax_clipped)), reference_answers])\n",
    "\n",
    "    return xentropy\n",
    "\n",
    "def grad_softmax_crossentropy_with_logits(logits,reference_answers):\n",
    "    \"\"\"\n",
    "    Compute cross-entropy gradient from output logits [batch,n_classes] and reference_answers [batch].\n",
    "    Note that the reference_answers are not one-hot labels. Instead, they are the index of the categories, e.g., 2 instead of [0,0,1].\n",
    "    d loss / d y = predicted_output - true_output\n",
    "    gradient is with the respect to the raw output of the output layer\n",
    "    \"\"\"\n",
    "    norm = np.exp(logits - np.max(logits, axis=1, keepdims=True))\n",
    "    softmax = norm / np.sum(norm, axis=1, keepdims = True)\n",
    "    \n",
    "    samples = len(logits)\n",
    "    grad_input = softmax.copy()\n",
    "    grad_input[range(samples), reference_answers] -= 1\n",
    "    grad_input = grad_input / samples\n",
    "\n",
    "    return grad_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Network and Forward pass (1 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XErb4TrFjw8G"
   },
   "source": [
    "First, we define network as a list of layers, each applied on top of previous one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "TOVs-C5pjw8G",
    "tags": []
   },
   "outputs": [],
   "source": [
    "network = []\n",
    "network.append(Fully_connected(1000, 256))\n",
    "network.append(ReLU())\n",
    "network.append(Fully_connected(256, 64))\n",
    "network.append(ReLU())\n",
    "network.append(Fully_connected(64, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we implement the forward pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "qUD5bRhBjw8G",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def forward(network, X):\n",
    "    \"\"\"\n",
    "    Compute the output of all network layers by applying them sequentially.\n",
    "    Note that we should return a list of outputs for each layer since we need them for backwrad pass.\n",
    "    \"\"\"\n",
    "    outputs = []\n",
    "    input = X\n",
    "    \n",
    "    for layer in network:\n",
    "        input = layer.forward(input)\n",
    "        outputs.append(input)\n",
    "\n",
    "    return outputs\n",
    "\n",
    "def predict(network, X):\n",
    "    \"\"\"\n",
    "    Use network to predict the result for each sample. Since we are doing classification, the result should be the index of the most likely class.\n",
    "    \"\"\"\n",
    "    outputs = forward(network, X)\n",
    "    last_layer = outputs[-1]\n",
    "    \n",
    "    norm = np.exp(last_layer - np.max(last_layer, axis=1, keepdims=True))\n",
    "    softmax = norm / np.sum(norm, axis=1, keepdims=True)\n",
    "    \n",
    "    prediction = np.argmax(softmax, axis=1)\n",
    "\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LdwEd2Gwjw8G"
   },
   "source": [
    "### 1.5. Train and Backprop (2 pts)\n",
    "\n",
    "We implement the training function here. The function takes a network, network input X, and ground truth y as the inputs.\n",
    "When calling this function, we want to have a forward pass and a backward pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Yd92p8kMjw8H",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(network,X,y):\n",
    "    \"\"\"\n",
    "    Train your network on a given batch of X and y only once.\n",
    "    Here are the steps to train once:\n",
    "    1. Run forward to get all layer outputs.\n",
    "    2. Estimate loss and loss_grad.\n",
    "    3. Run layer.backward going from last layer to first.\n",
    "\n",
    "    Note that after you called backward for all layers, the layers with trainable parameters should have already updated.\n",
    "    \"\"\"\n",
    "    # Run forward to get outputs of all layers\n",
    "    layer_outputs = forward(network, X)\n",
    "    \n",
    "    # Get a list of all layer inputs\n",
    "    layer_inputs = []\n",
    "    layer_inputs.append(X)\n",
    "    for i in range(len(layer_outputs)-1):\n",
    "        layer_inputs.append(layer_outputs[i])\n",
    "        \n",
    "    logits = layer_outputs[-1]\n",
    "\n",
    "    # Compute the loss and the initial gradient\n",
    "    loss = softmax_crossentropy_with_logits(logits, y)\n",
    "     \n",
    "    grad_outputs = []\n",
    "    grad_output = grad_softmax_crossentropy_with_logits(logits, y)\n",
    "    grad_outputs.append(grad_output)\n",
    "\n",
    "    # Propagate gradients through network layers using .backward\n",
    "    j = len(layer_inputs) - 1\n",
    "    k = 0\n",
    "    for layer in reversed(network):\n",
    "        g_o = layer.backward(layer_inputs[j], grad_outputs[k])\n",
    "        grad_outputs.append(g_o)\n",
    "        j = j - 1\n",
    "        k = k + 1\n",
    "        \n",
    "    return np.mean(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NwAmZNidjw8H"
   },
   "source": [
    "## 2. Test your network (2 pt)\n",
    "\n",
    "In this homework, we use a single-cell dataset: Pancreas Dataset. Our task is to classify cells to cell types based on the gene expression information. There are 8 different cell types. Cells are samples, genes are features, and cell types are classes.\n",
    "\n",
    "You need to load the data from '.csv' and implement a simple dataloader. (If you do not remember why we need a dataloader, you can check Exercise 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load input data from 'data.csv'. Data in csv has 8391 rows and 1000 columns\n",
    "data = np.loadtxt(\"DLB/HW1/data.csv\", dtype=float, delimiter=\",\")\n",
    "# Standardizing the data for better training\n",
    "data = (data - np.mean(data, axis=0))/(np.std(data, axis=0)+1e-7)\n",
    "\n",
    "# 8391 rows mean there are 8391 cells.\n",
    "# 1000 columns mean 1000 genes are measured for each cell.\n",
    "\n",
    "# There are 8391 strings in 'label.csv', and they are the cell type of the 8391 cells.\n",
    "# The input data and labels are aligned:\n",
    "# For example, the first string in 'label.csv' is the cell type of the first cell (frist row of data) of 'data.csv'\n",
    "# In other words, data[0] and cell_type_per_sample[0] should be paired.\n",
    "\n",
    "cell_type_per_sample = np.loadtxt(\"DLB/HW1/label.csv\", dtype=str, delimiter=\",\")\n",
    "\n",
    "# Get integer labels from the cell types of data type string\n",
    "\n",
    "values = np.unique(cell_type_per_sample)\n",
    "labels = np.zeros(cell_type_per_sample.size, dtype=int)\n",
    "\n",
    "for value in values:\n",
    "    i = np.where(values == value)[0][0]\n",
    "    ind = np.where(cell_type_per_sample == value)[0]\n",
    "    labels[ind] = i\n",
    "\n",
    "# Split train and val data. You can choose the ratio of splitting, and you can decide whether to shuffle the data or not.\n",
    "index = round(0.8*np.shape(data)[0])\n",
    "X_train, X_val = data[:index, :], data[index:, :]\n",
    "y_train, y_val = labels[:index], labels[index:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have the training and test data. We need a dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "iHuBzg4Djw8H",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# A mini-dataloader\n",
    "from tqdm import trange\n",
    "\n",
    "# Note: function signatures should remain the same, but the skeleton is just a guide and can be changed.\n",
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n",
    "    \n",
    "    assert len(inputs) == len(targets)\n",
    "\n",
    "    if shuffle:\n",
    "        # re-order the indices for shuffling the samples\n",
    "        indices = np.random.permutation(np.arange(len(targets)))\n",
    "    \n",
    "    for start_idx in trange(0, len(inputs) - batchsize + 1, batchsize):\n",
    "\n",
    "        # Get indexs for the current mini-batch\n",
    "        if shuffle:\n",
    "            indexs = indices[start_idx:start_idx+batchsize]\n",
    "        else:\n",
    "            indexs = np.arange(start_idx, start_idx+batchsize, 1, dtype=int)\n",
    "\n",
    "        yield inputs[indexs], targets[indexs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, test your model! You should get a more than 90% accuracy for training data and a more than 85% accuracy for validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 481
    },
    "id": "3FOu8r1Qjw8H",
    "outputId": "1f76da29-96ca-4518-9499-b6a324cf898c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9\n",
      "Train accuracy: 0.984954565767913\n",
      "Val accuracy: 0.8963051251489869\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "train_log = []\n",
    "val_log = []\n",
    "\n",
    "for epoch in range(10):\n",
    "\n",
    "    for x_batch,y_batch in iterate_minibatches(X_train, y_train, batchsize=256, shuffle=True):\n",
    "        train(network, x_batch, y_batch)\n",
    "\n",
    "    train_log.append(np.mean(predict(network, X_train) == y_train))\n",
    "    val_log.append(np.mean(predict(network, X_val) == y_val))\n",
    "\n",
    "    clear_output()\n",
    "    print(\"Epoch\",epoch)\n",
    "    print(\"Train accuracy:\",train_log[-1])\n",
    "    print(\"Val accuracy:\",val_log[-1])\n",
    "\n",
    "plt.plot(train_log,label='train accuracy')\n",
    "plt.plot(val_log,label='val accuracy')\n",
    "plt.legend(loc='best')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "264px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
