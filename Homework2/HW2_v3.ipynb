{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9769780-6a67-4060-bbba-15c46d840f99",
   "metadata": {},
   "source": [
    "# Deep learning in biomedicine, CS-502\n",
    "## HW02, Marija Zelic, SCIPER 371272"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d49c4d3-ac0b-4733-a420-48e70c588b58",
   "metadata": {},
   "source": [
    "Purpose of this homeowork is to build and compare different GNN models to implement graph classification. The dataset that is used is MUTAG dataset that containes 188 small graphs that represent nitroaromatic molecules, some of which have mutagenetic effect on bacteria *Salmonella typhimurium'* (class 1) and some not (class 0). Our first task is to obtain the data set and load it to the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b298e32-b725-4d3e-8e8f-0eabf223168b",
   "metadata": {},
   "source": [
    "## 1. Dataloader for MUTAG dataset  \n",
    "\n",
    "Data can be loaded directly using datasets library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1064,
   "id": "1b3c3a3e-ec70-4eec-8df9-96d11c75db5d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcc38fc0877e44f79660d47752feecbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/3.88k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/graphs-datasets--MUTAG (download: 345.60 KiB, generated: 582.78 KiB, post-processed: Unknown size, total: 928.38 KiB) to /Users/marijazelic/.cache/huggingface/datasets/graphs-datasets___json/graphs-datasets--MUTAG-a0cf78a2615b5c11/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b52b0b890e6b4fc8a7dcc3aecaacad72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cca08ec48be942799bcbb75a34df7d37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/354k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1a7b7d246c643d68032fc466413f1fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/188 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /Users/marijazelic/.cache/huggingface/datasets/graphs-datasets___json/graphs-datasets--MUTAG-a0cf78a2615b5c11/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "import huggingface_hub\n",
    "\n",
    "from datasets import load_dataset\n",
    "from datasets import Dataset\n",
    "\n",
    "from scipy import sparse as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import networkx as nx\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning) # because of nx.adjacency_matrix\n",
    "\n",
    "dataset = load_dataset(\"graphs-datasets/MUTAG\",split=\"train\", download_mode='force_redownload')  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ba1d96-673f-479e-ba64-c3b174cdf87a",
   "metadata": {},
   "source": [
    "Each element in *dataset* variable contains:  \n",
    "* **node_features** - list of shape (#nodes, #node_features), containing initial node embeddings\n",
    "* **edge_index** - list of shape (2, #edges), containing all of the edges between the nodes\n",
    "* **edge_attr** - list of shape (#edges, #edge_features), containing edge features\n",
    "* **y** - label 0 or 1 for classifying each molecule\n",
    "* **num_nodes** - number of nodes that graph (molecule) has  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1267f5c-30c0-4016-b755-be868e0b1a90",
   "metadata": {},
   "source": [
    "Let's visualise one of the graphs (molecules) so that would be easier for us to percieve it. We need to convert it to *networkx* type Graph so we can use its functions for plotting graphs.  \n",
    "As we are going to use PyTorch library, it would be more conveniet for us to convert all of the data to *torch* type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1065,
   "id": "1728053d-50fe-41cb-99e2-8d2a9e6e135f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.set_format(type='torch', columns=['edge_index', 'node_feat', 'edge_attr', 'y', 'num_nodes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099cab0c-6a46-4a0b-bb18-d6b173bb0671",
   "metadata": {},
   "source": [
    "We can output the *y* parameter that represents class label for each of the graphs in the dataset. This can be useful because we can see how many samples belong to the one or the other class, i.e. whether classes are balanced or not. Deriving this conclusion will give us an important insight into structure of the dataset, which can help us for making better network arhitecture for classification.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1066,
   "id": "faf9f48a-49e6-4ef1-b416-00ff47533dfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: 63\n",
      "Class 1: 125\n"
     ]
    }
   ],
   "source": [
    "classes = dataset['y'].squeeze(-1)\n",
    "\n",
    "# It's more convenient to just count the number of graphs per class\n",
    "# We will make torch.zeros tensor of the same length as the dataset and compare elements to determine number of graphs per\n",
    "comparison0 = torch.zeros(len(dataset), dtype=int)\n",
    "comparison1 = torch.ones(len(dataset), dtype=int)\n",
    "\n",
    "class_0 = torch.eq(classes, comparison0)\n",
    "class_1 = torch.eq(classes, comparison1)\n",
    "\n",
    "num_class_0 = class_0.sum()\n",
    "num_class_1 = class_1.sum()\n",
    "\n",
    "# Bar to compare number of graphs per class\n",
    "names = ['class 0', 'class 1']\n",
    "numbers = [num_class_0, num_class_1]\n",
    "fig = plt.figure()\n",
    "plt.bar(names, numbers, color ='maroon', width = 0.4)\n",
    "plt.title(\"Number of graphs per class\")\n",
    "plt.grid(visible=True)\n",
    "plt.savefig(\"classes.png\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"Class 0: {num_class_0:d}\")\n",
    "print(f\"Class 1: {num_class_1:d}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3036f5c5-1de7-4e31-bb1b-86e0548c6bb6",
   "metadata": {},
   "source": [
    "From the previous plot we can conclude that classes are imbalanced as class labeled with 1 has almost twice as much graphs as the class 0. This will lead to the problems with classification as the learning algorithm will have better generalization for the graphs in the class 1. We have a couple of ways we can deal with such an issue, but we will focus more on that when we reach the point of an actual model training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e41b544-1562-4225-b2f7-0825920cb7f3",
   "metadata": {},
   "source": [
    "It will be very convenient for the later to implement the function that uses the provided data to convert the graph into an *nx.Graph* object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1067,
   "id": "eb8ec2ee-c672-401a-910e-b4b655725a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_graph(dataset_element):\n",
    "    \"\"\" \n",
    "    Converts dataset element to graph.\n",
    "    \n",
    "    Args: \n",
    "        dataset_element (dict): one graph with params node_feat, edge_index, edge_feat\n",
    "        \n",
    "    Returns:\n",
    "        graph (nx.graph): element of dataset converted to the graph\n",
    "        \n",
    "    \"\"\"\n",
    "    graph = nx.Graph()\n",
    "    \n",
    "    # We extract the information about the number of nodes \n",
    "    num_nodes = dataset_element['node_feat'].squeeze(0).size(dim=0)\n",
    "    nodes = np.arange(num_nodes)\n",
    "    nodes = nodes.tolist()\n",
    "    \n",
    "    # Add the nodes to the graph\n",
    "    graph.add_nodes_from(nodes)\n",
    "    \n",
    "    # Add the edges to the graph\n",
    "    edge_list = dataset_element['edge_index'].squeeze(0).tolist()\n",
    "    new_edge_list = []\n",
    "    dim = len(edge_list[0])\n",
    "    \n",
    "    for i in range(dim):\n",
    "        new_edge_list.append([edge_list[0][i], edge_list[1][i]])\n",
    "\n",
    "    graph.add_edges_from(new_edge_list)\n",
    "    return graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1068,
   "id": "73f5c891-be60-4f40-a581-3ff155948e4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAAGZCAYAAAAUzjLvAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAB3gUlEQVR4nO3dd1hT5xcH8O9NAoGwh6AgwwlWEa0DxYFYZx2tq+K2ddZVbW0drbtFW221VWvrqlvanxW01q2IA8VV9x4QKsoIMgOBJO/vD4SKrAAJNyHn8zw+LbnrJITk3HvPe16OMcZACCGEEKMl4DsAQgghhPCLkgFCCCHEyFEyQAghhBg5SgYIIYQQI0fJACGEEGLkKBkghBBCjBwlA4QQQoiRo2SAEEIIMXKUDBBCCCFGzqiTgRs3bmDMmDGoV68ezM3NYW5ujgYNGmDChAm4fPkyr7F5enqid+/evMZQ3UVGRmLhwoVISUmp8D4OHjyIhQsXFrvM09MTo0ePrvC+q8I///yDgIAA2NjYgOM4rFq1qtj15HI5Fi5ciFOnThVZtnDhQnAch6SkJN0GW4U4jivx91qVtmzZAo7jEB0dXWXH1MbfRWXduXMHCxcurNLnbeyMNhn49ddf0aJFC0RFReGTTz7BgQMH8Pfff2P69Om4ffs2WrVqhcePH/MdJtGhyMhILFq0qNLJwKJFi4pdFhoainnz5lV431Xho48+wvPnzxESEoLz588jKCio2PXkcjkWLVpUbDJAqhdt/F1U1p07d7Bo0SJKBqqQiO8A+HDu3DlMmjQJvXr1wp49e2BqalqwrHPnzpg8eTL+97//wdzcvNT9yOVySCQSXYerFSqVCkqlEmKxuEqOZ0ivja40b96c7xDKdOvWLYwbNw49e/bkOxRioLKyssr8rNQXubm54DgOIpFRfvWVjhmhd999l5mYmLC4uDiNtxk1ahSzsLBgN27cYF27dmWWlpasTZs2jDHGjh49yvr27ctcXV2ZWCxm9erVY+PHj2eJiYmF9rFgwQIGgF29epX169ePWVlZMWtrazZs2DCWkJBQaF0PDw/Wq1cvdujQIda8eXNmZmbGvLy82KZNm8qM9enTpwwA+/bbb9mSJUuYp6cnEwqF7NChQ4wxxi5dusT69OnD7OzsmFgsZs2aNWO///57oX389ttvDAA7evQoGz16NLOzs2MSiYT17t2bPX78uNC6AQEBrHHjxiwiIoK1bduWmZubs8GDBzPGGEtNTWWfffYZ8/T0ZCYmJszFxYV98sknLCMjo9A+/vjjD9a6dWtmbW3NzM3NWZ06ddiHH35YaB1N9wWATZ48mW3bto15e3szc3Nz1rRpU/bXX38V+V28+S88PJwxxlhISAjr2rUrq1mzJjMzM2Pe3t5s1qxZhY41atSoYvfx9OnTgt/hqFGjCsUWExPDhg0bxmrUqMFMTU2Zt7c3W7FiBVOpVEV+f8uXL2fff/898/T0ZBYWFqxNmzbs/Pnzpf3qC9y8eZP17duX2draMrFYzHx9fdmWLVsKluf/ft/8V5z8eN78l//c8l/LW7dusaCgIGZtbc2cnJzYhx9+yFJSUgrtS61Ws7Vr1zJfX19mZmbGbG1t2YABA4q8p4qTf5zr16+zgQMHMmtra2ZnZ8dmzJjBcnNz2b1791j37t2ZpaUl8/DwYN9++22RfWjy+jOW9x5asGBBoceeP3/Oxo8fz1xdXZmJiQnz9PRkCxcuZLm5uYXWy87OZosWLWLe3t5MLBYze3t71qlTJ3bu3LlCr+dvv/1WJL43j5v/e8p/T+U7duwY69y5M7OysmLm5ubM39+fHT9+vMzXUKVSsSVLlrCGDRsyMzMzZmNjw3x8fNiqVasKvcYl/V3kfy79+eefrFmzZkwsFrNZs2aV6zkxxtjdu3dZUFAQc3JyYqampszNzY2NGDGCZWdnl/jezN93cX9XjOV9DgUEBBT8HB4ezgCwbdu2sU8//ZS5uLgwjuPY3bt3K/UaVldGlwwolUpmbm7O2rZtW67tRo0aVfABsHTpUnbixAl25MgRxhhj69atY0uXLmX79+9nERERbOvWrczX15d5eXmxnJycgn3k/6F5eHiwzz//nB05coT98MMPzMLCgjVv3rzQuh4eHqx27drsrbfeYtu2bWNHjhxhgwYNYgBYREREqbHm/2G6urqywMBAtmfPHnb06FH29OlTdvLkSWZqaso6dOjAfv/9d3b48GE2evToIn/I+X+Qbm5u7KOPPmKHDh1i69evZ05OTszNzY29fPmyYN2AgABmb2/P3Nzc2OrVq1l4eDiLiIhgmZmZrFmzZszR0ZH98MMP7Pjx4+zHH39kNjY2rHPnzkytVjPGGIuMjGQcx7GgoCB28OBBdvLkSfbbb7+xESNGFBxD030xlvfh4+npyVq3bs3++OMPdvDgQdapUycmEokKvnRiY2PZ1KlTGQC2d+9edv78eXb+/HmWmprKGGNsyZIlbOXKlezvv/9mp06dYr/88gurU6cOCwwMLDjOo0eP2MCBAxmAgu3Pnz/PsrOzC36Hr39oJSQkMFdXV1ajRg32yy+/sMOHD7MpU6YwAOzjjz8u8vvz9PRkPXr0YGFhYSwsLIz5+PgwOzu7Il+wb7p37x6zsrJi9erVY9u2bWN///03GzJkSEGCmB/L+fPnGQA2cODAgtiLk52dzQ4fPswAsDFjxhSs++jRI8bYf+9rLy8vNn/+fHbs2DH2ww8/MLFYXCShGzduHDMxMWGfffYZO3z4MNu1axfz9vZmzs7O7MWLF6U+r9ePs2TJEnbs2DH2xRdfMABsypQpzNvbm/3000/s2LFj7MMPP2QA2J9//lnu15+xol9gz58/Z25ubszDw4P9+uuv7Pjx42zJkiVMLBaz0aNHF6yXm5vLAgMDmUgkYjNnzmQHDx5k+/fvZ3PnzmW7d+8u9PutaDKwfft2xnEce//999nevXvZX3/9xXr37s2EQmGZX2ZLly5lQqGQLViwgJ04cYIdPnyYrVq1ii1cuJAxVvbfhYeHB6tVqxarW7cu27x5MwsPD2cXL14s13O6du0as7S0ZJ6enuyXX35hJ06cYDt27GAffPABS0tLYwkJCSw4OJgBYGvXri2IIf+EqbzJgKurKxs4cCDbv38/O3DgAJPJZJV6Dasro0sGXrx4wQCwoKCgIsuUSiXLzc0t+Pf6F0z+WeDmzZtL3b9arWa5ubksJiaGAWD79u0rWJb/YTZjxoxC2+zcuZMBYDt27Ch4zMPDg5mZmbGYmJiCx7Kyspi9vT2bMGFCqTHk/2HWq1evUILBGGPe3t6sefPmRc5mevfuzWrVqlVwhpT/IdSvX79C6507d44BYF9//XXBYwEBAQwAO3HiRKF1ly5dygQCAbt06VKhx/fs2cMAsIMHDzLGGFuxYgUDUOqXnKb7Yizvw8fZ2ZmlpaUVPPbixQsmEAjY0qVLCx5bvnx5sWddb8r/nUZERBScmeabPHlyiWfUb35ozZ49mwFgUVFRhdb7+OOPGcdx7P79+4yx/35/Pj4+TKlUFqx38eJFBqDgS6UkQUFBTCwWM6lUWujxnj17MolEUuh1zr+KUpbExMRiz/AY++99/d133xV6fNKkSczMzKzg7yg/+fj+++8LrRcbG8vMzc3ZF198UWoM+cd5c/tmzZoVfHnly83NZTVq1GD9+/cveEzT15+xol9gEyZMYJaWloX+Hhn77717+/Ztxhhj27ZtYwDYhg0bSnwelUkGMjMzmb29PevTp0+h7VQqFfP19WWtW7cu8biM5f2dN2vWrNR1Svu78PDwYEKhsNBrVd7n1LlzZ2Zra1vkaujr/ve//xW6IvFmDOVJBjp27Fhovcq+htWV0RYQFqdFixYwMTEp+Pf9998XWWfAgAFFHktISMDEiRPh5uYGkUgEExMTeHh4AADu3r1bZP1hw4YV+vmDDz6ASCRCeHh4ocebNWsGd3f3gp/NzMzQsGFDxMTEaPR8+vbtCxMTk4KfHz16hHv37hUcX6lUFvx799138fz5c9y/f7/UWP39/eHh4VEkVjs7O3Tu3LnQYwcOHECTJk3QrFmzQsfq3r07OI4rKEZr1apVwevwxx9/4NmzZ0Wei6b7yhcYGAgrK6uCn52dneHk5KTxa/fkyRMMHToUNWvWhFAohImJCQICAgAU/zvVxMmTJ/HWW2+hdevWhR4fPXo0GGM4efJkocd79eoFoVBY8HPTpk0BoMzncPLkSbzzzjtwc3Mrchy5XI7z589XKP6y9O3bt9DPTZs2RXZ2NhISEgDk/Q45jsPw4cML/Q5r1qwJX19fjYsT3xxl06hRI3AcV6juQSQSoX79+oVeq/K+/q87cOAAAgMD4eLiUij2/GNGREQAAA4dOgQzMzN89NFHGj2X8oqMjERycjJGjRpVKA61Wo0ePXrg0qVLyMzMLHH71q1b4/r165g0aRKOHDmCtLS0csfQtGlTNGzYsELxy+VyRERE4IMPPkCNGjUqtI/yevMzu7KvYXVldFUUjo6OMDc3L/YDddeuXZDL5Xj+/HmRDzYAkEgksLa2LvSYWq1Gt27dEBcXh3nz5sHHxwcWFhZQq9Vo06YNsrKyiuynZs2ahX4WiURwcHCATCYr9LiDg0ORbcVicbH7LE6tWrUK/RwfHw8AmDlzJmbOnFnsNm8OD3sz1vzH3oz1zWPlH+/Ro0eFEpLijtWxY0eEhYXhp59+wsiRI6FQKNC4cWN8+eWXGDJkSLn2la8yr11GRgY6dOgAMzMzfP3112jYsCEkEgliY2PRv39/jV//N8lkMnh6ehZ53MXFpWB5ac8hv/izrOPLZLJifx8lHUdbyoo3Pj4ejDE4OzsXu33dunU1Oo69vX2hn01NTSGRSGBmZlbk8de/7Mr7+r8uPj4ef/31V5nvv8TERLi4uEAg0M15Vv7f8MCBA0tcJzk5GRYWFsUumzNnDiwsLLBjxw788ssvEAqF6NixI7799lu0bNlSoxiKe29p6uXLl1CpVKhdu3aF91FeJX0OVvQ1rK6MLhkQCoXo3Lkzjh49iufPnxd6o7z11lsAUOJwFo7jijx269YtXL9+HVu2bMGoUaMKHn/06FGJMbx48QKurq4FPyuVSshksmK/wCrjzXgdHR0B5H0g9O/fv9htvLy8isT6phcvXqB+/fqlHiv/eObm5ti8eXOxx8qPBwDee+89vPfee1AoFLhw4QKWLl2KoUOHwtPTE23bti3Xvirr5MmTiIuLw6lTpwquBgCo9FArBwcHPH/+vMjjcXFxALT3HKrqOOXl6OgIjuNw5syZYke16HqkS2VeF0dHRzRt2hTffPNNscvzE4oaNWrg7NmzUKvVJSYE+UmLQqEo9LgmSVp+jKtXr0abNm2KXaekZAvIO/H49NNP8emnnyIlJQXHjx/H3Llz0b17d8TGxmo0Aqi4v3VNn5O9vT2EQiH+/fffMo9TEjMzsyLHAfISsuJ+hyV9Dlb0NayujC4ZAPK+DA8dOoSJEydiz549JWb7msh/o735Qfbrr7+WuM3OnTvRokWLgp//+OMPKJVKdOrUqcJxaMLLywsNGjTA9evXERwcrNE2O3fuLHSZLTIyEjExMRg7dmyZ2/bu3RvBwcFwcHBAnTp1NDqeWCxGQEAAbG1tceTIEfzzzz9o27ZthfalybGAomfa5fmdvr6PsoZXvfPOO1i6dCmuXr2Kt99+u+Dxbdu2geM4BAYGlv9JlHCc0NBQxMXFFXxJ5R9HIpGU+AFYGk2vSpSmd+/eWLZsGZ49e4YPPvigwvupqMq8/r1798bBgwdRr1492NnZlbhez549sXv3bmzZsqXEWwXOzs4wMzPDjRs3Cj2+b9++Mp9Du3btYGtrizt37mDKlCllrl8aW1tbDBw4EM+ePcP06dMRHR2Nt956q0K/a02fk7m5OQICAvC///0P33zzTYkJWGkxeHp6FjnOgwcPcP/+fY0SXW2+htWJUSYD7dq1w9q1azF16lS8/fbbGD9+PBo3bgyBQIDnz5/jzz//BIAitwSK4+3tjXr16mH27NlgjMHe3h5//fUXjh07VuI2e/fuhUgkQteuXXH79m3MmzcPvr6+VfIB+euvv6Jnz57o3r07Ro8eDVdXVyQnJ+Pu3bu4evUq/ve//xVa//Llyxg7diwGDRqE2NhYfPnll3B1dcWkSZPKPNb06dPx559/omPHjpgxYwaaNm0KtVoNqVSKo0eP4rPPPoOfnx/mz5+Pf//9F++88w5q166NlJQU/Pjjj4Xu02u6r/Lw8fEBAPz4448YNWoUTExM4OXlBX9/f9jZ2WHixIlYsGABTExMsHPnTly/fr3EfXz77bfo2bMnhEIhmjZtWqh3Rb4ZM2Zg27Zt6NWrFxYvXgwPDw/8/fff+Pnnn/Hxxx9X+D7smxYsWFBwj3v+/Pmwt7fHzp078ffff+O7776DjY1NufdpZWUFDw8P7Nu3D++88w7s7e3h6OhY7GX3krRr1w7jx4/Hhx9+iMuXL6Njx46wsLDA8+fPcfbsWfj4+ODjjz8ud2yaqszrv3jxYhw7dgz+/v6YNm0avLy8kJ2djejoaBw8eBC//PILateujSFDhuC3337DxIkTcf/+fQQGBkKtViMqKgqNGjVCUFBQQd3E5s2bUa9ePfj6+uLixYvYtWtXmc/B0tISq1evxqhRo5CcnIyBAwfCyckJiYmJuH79OhITE7Fu3boSt+/Tpw+aNGmCli1bokaNGoiJicGqVavg4eGBBg0aACj57+L1Gpw3lec5/fDDD2jfvj38/Pwwe/Zs1K9fH/Hx8di/fz9+/fVXWFlZoUmTJgCA9evXw8rKCmZmZqhTpw4cHBwwYsQIDB8+HJMmTcKAAQMQExOD7777TuMahMq+htUWv/WL/Lp27Rr78MMPWZ06dZhYLGZmZmasfv36bOTIkUUq4/P7DBTnzp07rGvXrszKyorZ2dmxQYMGMalUWqSKNr8a+sqVK6xPnz7M0tKSWVlZsSFDhrD4+PhC+8wfz/umNytmi/P6OPXiXL9+nX3wwQfMycmJmZiYsJo1a7LOnTuzX375pWCd1/sMjBgxgtna2jJzc3P27rvvsocPHxaJqXHjxsUeKyMjg3311VfMy8uLmZqaFoxrnjFjRsFQsgMHDrCePXsyV1dXZmpqypycnNi7777Lzpw5U+59MVZyhXxxVchz5sxhLi4uTCAQFKpejoyMZG3btmUSiYTVqFGDjR07ll29erVIxbRCoWBjx45lNWrUYBzHadRnYOjQoczBwYGZmJgwLy8vtnz58hL7DLzpzfdUSW7evMn69OnDbGxsmKmpKfP19S2x0luT0QSMMXb8+HHWvHlzJhaLi+0z8GZfjZLGyG/evJn5+fkxCwsLZm5uzurVq8dGjhzJLl++XOrxSzpOSX+bxb0vNXn9GSv+dU5MTGTTpk1jderUYSYmJsze3p61aNGCffnll4X6T2RlZbH58+ezBg0aMFNTU+bg4MA6d+7MIiMjC9ZJTU1lY8eOZc7OzszCwoL16dOHRUdHa9xnICIigvXq1YvZ29szExMT5urqynr16sX+97//lfoafv/998zf3585OjoyU1NT5u7uzsaMGcOio6MLrVfS30VJn0vleU6M5X1mDho0iDk4OBTEMXr06IJhuYwxtmrVKlanTh0mFAoL/d2p1Wr23Xffsbp16zIzMzPWsmVLdvLkyRJHE5T0mlT0NayuOMYYq8rkw5gtXLgQixYtQmJiIm/3bTW1ZcsWfPjhh7h06ZLGhUWEEEIMEw0tJIQQQowcJQOEEEKIkaPbBIQQQoiRoysDhBBCiJGjZIAQQggxchr1GVCr1YiLi4OVlVWx3acIIYQQon8YY0hPTy+zTbZGyUBcXFyRSU8IIYQQYhhiY2NLnRNCo2Qgv/NUbGysRl35CCGEEMK/tLQ0uLm5ldpBEtAwGci/NWBtbU3JACGEEGJgyrrFTwWEhBBCiJGjZIAQQggxcpQMEEIIIUaOkgFCCCHEyFEyQAghhBg5SgYIIYQQI0fJACGEEGLkKBkghBBCjBwlA4QQQoiRo2SAEEIIMXKUDBBCCCFGjpIBQgghxMhRMkAIIYQYOUoGCCGEECNHyQAhhBBi5CgZIIQQQoyciO8ACDEmmQolomWZyFGqYSoSwNPBAhZi+jMkhPCLPoUI0bGH8enYGSVF+P0ESJPlYK8t4wC420sQ6OWEYX7uaOBsxVeYhBAjxjHGWFkrpaWlwcbGBqmpqbC2tq6KuAgxeLHJcswNvYkzj5IgFHBQqUv+U8tf3qG+I4L7+cDNXlKFkRJCqitNv7+pZoAQHQi5JEWXlRGIfCIDgFITgdeXRz6RocvKCIRckuo8RkIIyUe3CQjRsjXhD7Hi6IMKbatSM6jUDLP33kRShgJTAhtoOTpCCCmKrgwQokUhl6QVTgTetOLoA/xOVwgIIVWAkgFCtCQ2WY4F+29rdZ/z999GbLJcq/skhJA30W0CQrRkbuhNKF/d+1cr5EiNDEFO/FPkxD+GOisNNu2GwLbDsCLbKV48Qkr4b1DE3QcEQph5NIVd5zEwsa0JpZphbuhNbB/jV9VPhxBiROjKACFa8DA+HWceJRUUAqqz0pF+7QiYKheShm1K3C5XFov4XXPAVErUeH8WHN/9BMrkZ4jf8QVU8lSo1AxnHiXhUUJ6VT0VQogRomSAEC3YGSWFUMAV/Cy0cYLb9BDUHLYMtgGjStwu5cxOcEITOA1aAPN6rSDx8ofToIVQydOQFrU3b18CDjsuUO0AIUR3KBkgRAvC7ycUGj7IcRw4jitlC4CpVch6dAkSL38IxP/1FRDZOMHMwwfyB+cB5I0wCH+QoJvACSEElAwQUmkZCiWkFSjyU758DqZUwNSpTpFlpjXqvFqeAwCQyuTIVCgrHSshhBSHkgFCKilGloky23gWQ5WVVwcgMLMsskxgbgmAQZWdAQBgAKJlmRUPkhBCSkHJACGVlKNUV24HpdxO4PDfskofhxBCSkDJACGVZCqq2J+R0DxvUiJ1VtGRAuqsDAAcBGYWlT4OIYSUhT5dCKkkTwcLlF4qWDyRXS1wIjFyEqOLLMtJjH613BRA3uyGng4WRdYjhBBtoGSAkEqyEIvgXoFZBjmBEOb1W0N+/zzUiv8KEJWpCciW3oDEy7/gMXcHCSzE1COMEKIblAwQogWBXk6F+gwAQNbjy8i8dxZZjy4CyGswlHnvLDLvnYU6NxsAYNthKJhSgYQ9i5H1+DLk9yORsGcRhObWsG7dD0Ben4HAhk5V+4QIIUaFY4yVWQit6XzIhBirh/Hp6LrqdKHH/v35I6jSiu8P4DpxE0S2zgBeb0d8L68dsfurdsR2tQrWPz6jI+o7WenuCRBCqiVNv7/puiMhWtDA2Qod6jvi3KNEqF9VENSetFmjbcU168N5yDfFLhNygH89R0oECCE6RbcJCNGCrKwsmFzbA2VuDlD2xTaNMMagzM1BJ4vnWtkfIYSUhJIBQirpxo0baNmyJXZvXIOeTuml9g0oD47j4JF4AWOH9MPkyZORnZ2tlf0SQsibKBkgpILUajVWrVqFVq1aQSgU4vLly/j1i1GY2a2hVvb/eTcvRPy2DGvWrMGmTZvg5+eHu3fvamXfhBDyOkoGCKmA58+f491338WMGTMwadIkXLx4EY0bNwYATAlsgGX9fSAWCYqMMCiLUMBBLBLg2/4+mBxYHxzHYfLkyYiKikJOTg5atmyJTZs2QYO6X0II0RglA4SU019//YWmTZvi2rVrOHToEFauXAkzM7NC6wS1csfxGQHwr+sAAGUmBfnL/es64PiMAAxu5V5oua+vLy5fvowhQ4Zg7NixGDJkCFJTU7X4rAghxoyGFhKiIblcjpkzZ2LdunXo3bs3Nm/ejBo1apS53cP4dOyMkiL8QQKkMnmhSY045DUUCmzohOFt3DUaNfD7779j/PjxcHBwwO7du+Hn51fxJ0UIqdY0/f6mZIAQDVy7dg1Dhw7F06dP8cMPP2DixIngKlAomKlQIlqWiRylGqYiATwdLCrUWfDJkycYOnQorly5gq+//hqff/45BAK60EcIKUzT72/69CCkFGq1Gj/88AP8/PxgamqKK1eu4OOPP65QIgDktS5u7GKD5u52aOxiU+EWw3Xr1sWZM2fw2WefYfbs2ejRowdevHhRoX0RQgglA4SU4Pnz5+jZsyc+++wzTJkyBVFRUXjrrbf4DquAiYkJli1bhqNHj+LGjRvw9fXFkSNH+A6LEGKAKBkgpBj79++Hj48Pbty4gSNHjuD777+HWCzmO6xide3aFdevX0fz5s3Ro0cPfPHFF8jJyeE7LEKIAaFkgJDXyOVyfPzxx3jvvffQrl073Lx5E926deM7rDI5Ozvj4MGDWL58OVauXIn27dvj8ePHfIdFCDEQlAwQ8so///yDFi1aYOvWrVi3bh3CwsLg6OjId1gaEwgEmDlzJiIjIyGTydC8eXPs3r2b77AIIQaAkgFi9NRqNb7//nv4+fnBzMwMV65cqfBoAX3QqlUr/PPPP+jTpw+GDh2Kjz76CJmZmXyHRQjRY5QMEKMWFxeH7t27Y+bMmZg2bRouXLiARo0a8R1WpVlbW2PHjh347bff8Pvvv6NFixa4du0a32ERQvQUJQPEaIWFhaFp06a4ffs2jh07hhUrVuhtkWBFcByH0aNH48qVKzAzM4Ofnx9Wr15NrYwJIUVQMkCMTmZmJiZMmIB+/fqhffv2uHHjBrp06cJ3WDrj7e2NCxcuYOLEiZg2bRref/99yGQyvsMihOgRSgaIQchUKHE7LhX/SF/idlwqMhXKCu3n6tWraNGiBbZv345ff/0VoaGhBlUkWFFmZmb48ccfsW/fPpw9exa+vr6IiIjgOyxCiJ6oWPszQqpAQU//+wmQJhfT099egkAvJwzzc0cD59J7+ucXCX755Zfw8fHB1atX4e3trdP49VHfvn1x/fp1DB8+HJ07d8ZXX32FefPmQSSijwJCjBnNTUD0TmyyHHNDb+LMoyQIBRxU6pLfovnLO9R3RHA/H7jZS4qs8+zZM4waNQonTpzA559/jq+//hqmpqa6fAp6T6VS4ZtvvsGiRYvQrl077Ny5E25ubnyHRQjRMpqbgBikkEtSdFkZgcgnefe0S0sEXl8e+USGLisjEHJJWmh5aGgomjZtirt37+L48eP47rvvjD4RAAChUIj58+fj1KlTePr0KXx9fREWFsZ3WIQQnlAyQPTGmvCHmL33JhRKdZlJwJtUagaFUo3Ze29iTfhDZGZmYvz48ejfvz8CAgJw48YNvPPOOzqK3HB16NAB169fR0BAAPr164fJkycjOzu7QvvSVl0HIaTq0W0CohdCLkkxe+9Nre1PdOV3PD/3J3788UeMGTPGYBsIVRXGGNatW4dPP/0UXl5eCAkJ0ajfgjbrOggh2qfp9zclA4R3sclydFkZAYVSrZX9McbAqZXY+kF9BLRsopV9GosbN24gKCgIMTEx+Omnn/DRRx8Vm0hpu66DEKIblAwQgzFiUxQin8iQm5WJ1MgQ5MQ/RU78Y6iz0mDTbghsOwwrtH527G1k3jyBnPjHyEmKAVRKuE7cBJGtc8E6QgEH/7oO2D7Gr6qfjsHLzMzE9OnTsXHjRgwePBi//vorbGxsCpaHXJJiwf7bUKpZuW7nCAUcRAIOi/o2RlArd12ETgh5AxUQEoPwMD4dZx4lQaVmUGelI/3aETBVLiQN25S4TXbMdWRFX4PQugbErsVfylapGc48SsKjhHRdhV5tWVhYYMOGDQgJCcGhQ4fQvHlzREVFAdBuXQchRH/Q4GLCq51R0oLLyEIbJ7hNDwHHcVDJU5Fx/Wix29i0C4Jt+6EAgNSovVBIi681EAo47LggxcK+jXUWf3U2ePBgtG7dGkOGDEH79u0xdN5aRGS5amXfK44+QA1LMQbTFQJC9AJdGSC8Cr+fUHCGyXGcRoV+HKfZ21alZgh/kFCp+IxdnTp1cObMGUyc+SXC0xwBLc5rMH//bcQmy7W2P0JIxdGVAcKbDIUSUh1/GUhlcmQqlLAQ01u9okxMTJBSvydEj5JQUomnIu4+Us7sgOLZPYAxmNZqANuOI2BW+60S96tUM8wNvUl1HYToAboyQHgTI8uErufPYwCiZZk6Pkr1ll/XUWIi8PwBXuycDZabA8fen8Kx96dgyhzE7/4Simd3S9wv1XUQoj8oGSC8ydHSUEJ9OU51lV/XUZKU0zsgMLOA0+BFkDRsC4mXP5wHL4HA1BwvT24udd/5dR2EEH5RMkB4YyqqmrdfVR2nunq9rqM4imd3YebuA4GJWcFjArEEZm5NoHh2F8qM5BK3pboOQvQDfUoS3ng6WEDXfQG5V8chFaNJXQdT5YITmhRdIMp7LDcxutTt8+s6CCH8oWSA8MZCLIK7jrvRuTtIqHiwEjSp6zBxcIci7j4Y++92DFOrkBN3HwCgziq9JoDqOgjhH31KEl4Fejlhe1RMwWXorMeXoc7NBsvJAgDkymKRee8sAMC8XksITMygkqci+1VvgfyzzqwnVyCQWEMosYGZuw+AvPvRgQ2dqvgZVS+a1FtYt+gN2aGfkHz0F9j4fwAwhtSzu6FMfXX5X4PholTXQQi/KBkgvBrm544t56MLfpYd+RmqtP/uIcvvnYX8VTLgOnETBLZmyE2MQVLYskL7ST76MwBA7NYENYflLVOpGYa3oaY2laFJvYWlbzeostKQGvk7Mv45CAAQu3rD2q8/0i7sgdDSQSvHIYToDiUDhFcNnK3Qob4jIp/IoFIz1J5UevU5AJh5NIXH7AOlrpM/N0F9J5oprzLy6zrKulVg02YgrFu+h9yXzyAwlUBk4wTZ4TXgTMxgWrN+qdtSXQch/KN0nPAuuJ8PRKUMXasIkYBDcD8fre7TGJWnroMTmcC0hidENk5QpiYg8+4ZWPp2h8BEXOp2VNdBCP8oGSC8c7OXYJGW5w9Y3LcxTZWrJYFeTqX2GchJjEbK2V2QP7qErOhrSIvai+dbpsPEzgW2HYeXum8BGAIaOGo7ZEJIOVE6TvRCUCt3JGUosOLog0rv6/NuXjQBjha9WdfxJk5oguyYG0i//BfUuVkQWdeAVfOesG4zCAJTsxK3AwA1OGybNxZ2T4IwZswYmiKdEJ5wjJU984im8yETUlkhl6RYsP82lGpWrilyhQIOIgGHxX0bUyKgAyM2RRXUdWiLUMChSQ0TWF/ZhpCQEJibm2Ps2LGYNm0aPD09tXYcQoyZpt/fdJuA6JWgVu44PiMA/nXzKtCZWlXq+vmXr/3rOuD4jABKBHREV3Uda0a2w/bt2xEdHY0pU6Zgy5YtqFevHgYNGoTIyEhocK5CCNECSgaI3nGzl2D7GD9MdE9Exj8HUdtWXKRTIQfAw0GCEX4eOD6jI7aP8aMaAR3SdV2Hq6srgoODERsbizVr1uDGjRto164d2rZti99//x1KJXUoJESX6DYB0Vu9e/dGWloaTp8+jUyFEtGyTOQo1TAVCeDpYEEV6DxYE/5Qa3UdkwNLHnKoVqtx8OBBrFy5EidPnoS7uzumTp2KsWPHwtbWttLHJ8RY0G0CYtDS09Nx/PhxvP/++wDyhrg1drFBc3c7NHaxoUSAJ1MCG2BZfx+IRYJSRxgURyjgIBYJ8G1/n1ITAQAQCATo3bs3Tpw4gX/++QeBgYGYO3cu3Nzc8Mknn+Dx48eVeRqEkDdQMkD00uHDh6FQKAqSAaI/8us6mtTIm4hIUEZLosrWdTRr1gxbtmxBTEwMpk+fjp07d6JBgwbo378/zpw5Q3UFhGgBJQNEL4WFhaFp06aoW7cu36GQYrjZS+Byfy9y9y3A8DYe8HCQ6Lyuo1atWliyZAliY2Pxyy+/4O7du+jYsSNat26NXbt2ITc3t1LPiRBjRjUDRO/k5OTAyckJ06dPx8KFC/kOhxQjIyMDLi4u+OSTT7BkyRIAqPK6DrVajSNHjmDlypU4duwYXF1dMXXqVIwfPx52dnY6Oy4hhoRqBojBOnXqFFJTU+kWgR77448/kJGRgTFjxhQ8VtV1HQKBAD179sTRo0dx48YNdO/eHfPnz0ft2rUxZcoUPHz4UKfHJ6Q6oWSA6J2wsDB4enrC19eX71BICdavX4/u3bvrTXMgHx8fbNq0CVKpFJ9//jn++OMPeHl54b333sOpU6eoroCQMlAyQPSKWq1GWFgY3n//fXCcdpvcEO24ceMGoqKiMH78eL5DKcLZ2RkLFy6EVCrFhg0b8PjxYwQGBqJFixbYvn07cnJy+A6REL1EyQDRK5cuXcLz58/pFoEe27BhA5ydndG7d2++QymRmZkZxowZg5s3b+LIkSNwdnbGyJEj4enpieDgYMhkMp0dO1OhxO24VPwjfYnbcanIVFDDJKL/qICQ6JXZs2dj06ZNeP78OUQi6iWgb+RyOVxcXDBp0iQEBwfzHU653LlzB6tWrcK2bdsgEAgwatQoTJ8+HV5eXpXe98P4dOyMkiL8fgKkyfJCgy05AO72EgR6OWGYnzsaOFtV+niEaErT729KBohe8fb2hr+/PzZv3sx3KKQYW7duxejRo/H48WODHfaZmJiIX375BWvXrkV8fDx69eqFGTNmoHPnzuW+NRWbLMfc0Js48ygJQgFX6kRO+cs71HdEcD8fap9NqgSNJiAG5+7du7h//z769evHdyikBOvXr0eXLl0MNhEAgBo1amDevHmIiYnBb7/9htjYWHTp0qWguZFCodBoPyGXpOiyMgKRT/JuOZQ1o2P+8sgnMnRZGYGQS9LKPRFCtIiSAaI3wsLCYGFhgS5duvAdCinG7du3ERkZqZeFgxUhFosxevRoXLt2DcePH4ebmxs+/PBDeHh4YMmSJUhMTCxx2zXhDzF7700olOpyT+usUjMolGrM3nsTa8Jp+CPRD5QMEL0RFhaGHj16wNzcnO9QSDE2bNiAGjVq4L333uM7FK3iOA7vvPMODhw4gLt376Jfv35YunQp3N3dMX78eNy5c6fQ+iGXpFqZrAkAVhx9gN/pCgHRA1QzQPTCs2fPULt2bWzfvh3Dhw/nOxzyhuzsbLi4uGDcuHH49ttv+Q5H52QyGX799VesWbMGz58/R48ePTBjxgx4t2iHrqtOQ6FUF9kmJ/4JUk5vQ05iDNTyVHAiU4jsXWH1dm9YNgks8VhikQDHZwRQDQHRCaoZIAZl3759EIlE6NWrF9+hkGL8+eefePnyJcaOHct3KFXCwcEBc+fORXR0NLZt24YXL16ge/fuCPxiPXKVqmK3UWdnQGjlCNuOI+E0aCEcen8KkY0zZAe+R8q5kBKPpVQzzA29qaunQohG6MoA0Qtdu3YFABw7doznSEhxAgICIBQKcfLkSb5D4QVjDLv+DseX57LKve3zbZ9BlZGM2pN+K3W94zM6or4TDTsk2kVXBojBePnyJU6dOkWNhvTUvXv3cPr06WpTOFgRHMfhodq5YDrm8hCaW4PjSv+oFQo47LhAtQOEP5QMEN79/fffUCqV1a4wrbrYuHEjHBwcjH7IZ/j9BI1GDjCmBlOroJKnIv3q38h6ehXWbQaWuo1KzRD+IEFboRJSbtTijfAuLCwMrVq1Qu3atfkOhbxBoVBgy5YtGDVqFMRiMd/h8CZDoYQ0Wa7RuslHfkbGtcN5PwhFsO8yAVbNe5a5nVQmR6ZCqfPZHgkpDr3rCK+ysrJw+PBhfPnll3yHQooRGhoKmUyGcePG8R0Kr2JkmdC0m4BN2w9g6dsdankK5I8uIvnYL1DnZsPGr3+p2zEA0bJMNHaxqXS8hJQXJQOEV8ePH0dmZibVC+ip9evXo2PHjvD29uY7FF7lFDOUsCQiGyeIbJwAAOb1WgEAUiK2wtLnHQglpX/Rl+c4hGgT1QwQXoWFhcHLywuNGjXiOxTyhocPHyI8PNzorwoAgKmo4h+V4loNAbUKypQXOj0OIZVB7zzCG6VSif3799NVAT21ceNG2NnZYcCAAXyHwjtPBwuUfxxBnuyYGwAngMi2Zqnrca+OQwgf6DYB4U1kZCSSkpKMvkpdH+Xk5OC3337DyJEjqT00AAuxCO72EsSUUkQoO7QaArEEprUaQmhhC5U8DfL7ZyG/ewbWfv3LvEXg7iDRWfFgpkKJaFkmcpRqmIoE8HSwoEJFUgi9GwhvwsLCUKtWLbRq1YrvUMgb9u/fj8TERLpF8JpALydsj4opcXih2NUbGTeOI+PmCagVmRCYmMHEqQ4cen9WajtiAGBqFV5cPYEtW2IQFBQEMzOzSsf7MD4dO6OkCL+fAGmyvFABJAfA3V6CQC8nDPNzRwNnanZk7KgDIeEFYwx169ZFjx49sG7dOr7DIW/o1q0bMjMzce7cOb5D0RsP49PRddVpne2//v3dOBG6E46OjpgwYQI+/vhjuLq6lns/sclyzA29iTOPkiAUcKX2Rshf3qG+I4L7+dD8CNUQdSAkeu3GjRuIjo6mWwR66MmTJzh27JhRdxwsTgNnK3So71ihLoSlEQo4dKjviON7d+D+/fsYOnQofvrpJ3h4eCAoKAjnzp2DBudsAPJmVOyyMgKRT2QAUGaTpPzlkU9k6LIyAiE0g6LRomSA8CI0NBQ2Njbo1KkT36GQN2zatAk2NjYYNGgQ36HoneB+PhBpORkQCTgE9/MBADRs2BA//vgj/v33X6xcuRJXr15F+/bt0bJlS2zduhXZ2dkl7mdN+EPM3nsTCqVao06Jr1OpGRRKNWbvvYk14Q8r9XyIYaJkgPAiLCwMvXr1gqmpKd+hkNfk5uZi8+bNGD58OCQSumT8Jjd7CRb1bazVfS7u27jI5Xlra2tMnToV9+7dw8GDB+Hk5ITRo0fD3d0d8+bNw7NnzwqtH3JJihVHH2glnhVHH+B3ukJgdCgZIFXu6dOnuH79Og0p1EMHDhzAixcvqHCwFEGt3DGzW0Ot7Ovzbl4Y3Mq9xOUCgQA9e/bEoUOHcO/ePQQFBWHVqlXw9PTEkCFDcP78eUhlmViw/7bGx0y/fgQxy3pD+n3J8yXM338bsRq2X+ZDpkKJ23Gp+Ef6ErfjUpGpUPIdksGjAkJS5VauXIk5c+YgMTERVlZUxaxP3n33XSQnJ+PChQt8h6L3Qi5JsWD/bSjVrHyX5dUqcEyN4IHNMaS1R7mPm5aWhi1btmD16tV49OgR6o/7ESqHulBr0AlBmZ6EuI2TITARQ62Qw/2zPcWuJxRw8K/rgO1j/Modn67Q6IiKoQJCorfCwsLQpUsXSgT0TExMDA4fPkxXBTQU1Modx2cEwL+uAwCUWViYv7xxDRP8u34i0q8dqdBxra2tMW3aNNy/fx8b/ziAXId6GiUCAJB8eC3M3BrDzLN5qeup1AxnHiXhUUJ6hWLUpthkOUZsikLXVaexPSoGMW8kAkDevA4xyXJsj4pB11WnMWJTlF5f2dBHlAyQKpWYmIizZ8/SLQI9tGnTJlhaWmLw4MF8h2Iw3Owl2D7GD8emd8QIPw94OEiKfC1zADwcJBjh54HjMzri75k9MXJAL3zxxRd4/vx5hY8tEAgQK/bUeHRDxq1wZMfegn23SRqtLxRw2HGB39oBGh1RdajpEKlSf/31Fxhj6Nu3L9+hkNcolUps2rQJw4YNg6WlJd/hGJwGzlZY2LcxFqKxRt3+li9fjgMHDmDq1KnYs6f4S/WaCL+foNEtClVmCl6e2AC7TqMhsnbUaN8qNUP4gwQshHYLJjW1JvxhhYsiVa9u3czeexNJGQpMCWyg5eiqH7oyQKpUaGgo2rVrBycnJ75DIa85dOgQ4uLiqLeAFliIRWjsYoPm7nZo7GJTbNtfe3t7/PTTT/jzzz+xb9++Ch0nQ6GEVMNL4clHf4aJvSssm79brmNIZXJeivNodETVo2SAVJmMjAwcO3aMGg3pofXr16NFixZo3rz0e8lEez744AP06tULkydPRlpaWrm3j5FlFrl3XpzMe+cgf3QR9j2nguPK1yOBAYiWZZY7tsqITZaXa3SEJvR9dIQ+oNsEpMocPnwYCoWC6gX0zL///ouDBw9SW+gqxnEcfv75ZzRu3Bhz5szB2rVry7V9jlJd5jrqnCwkH1sH6xZ9ILK0hzo7AwDA1Hln++rsDEAggsC05LkQdv/+P/h7ucDT0xMeHh6wsNDtzIpzQ29CWcKtj+yYG4jfPbfYZTVHrIDY1bvYZUo1w9zQm3o1OkLfUDJAqkxYWBiaNm2KunXr8h0Kec3mzZthbm6OIUOG8B2K0XF3d8c333yD6dOnY9iwYfD399d4W1NR2Rd21fI0qDNTkHYxFGkXQ4ssj10VBPMGbeA04KsS9/HD8u/wzfP/uhI6OjrC09Oz4J+Hh0eh/6/MKKGH8ek48yipzPVsA0bCzL1pocdMapQ8TPP10RH1nWgUU3EoGSBVIjc3FwcOHMAnn3zCdyjkNSqVChs3bsSQIUNoqCdPJk+ejF27dmHcuHG4evUqxGKxRtt5OliAA0q9VSC0tIPzkOAij6de2ANF7C04DVoIgaTkseccgBePbiJVloCYmBhER0cX/IuJiUFYWBhiYmKQm5tbsI2Dg0OhBOHNhKG0se47o6RlTq4EACI7lxKvApQkf3TEQi13kKwuKBkgVeLUqVNITU2legE9c+TIEcTGxlLhII+EQiE2bNiAt99+G99++y3mz5+v0XYWYhHc7SWIKeVeOCcyhZlH0yKPZ9w8AXCCYpe9zt1BAmuJGNYSN7i5uaF9+/ZF1lGr1Xj+/HlBgvB6wnDgwAHExMRAoVAUrG9nZ1ckQcj/+fhdWbnnVdAU36Mj9B0lA6RKhIWFwcPDA76+vnyHQl6zYcMGNGvWDC1btuQ7FKPm4+ODWbNm4ZtvvsGgQYPQqFEjjbYL9HLC9qgYnXyBCgUcAhuWPepHIBDA1dUVrq6uaNeuXZHlarUa8fHxha4o5P//oUOHEBMTg+zsbHCm5nCb8YdGRY7JR39B0r7vwJmIIXb1ho1/EMzcyv6Szx8dUdwID2NH7YiJzqnVari5uWHQoEFYtWoV3+GQV+Li4uDu7o6ffvoJkyZp1oiG6E52djZ8fX3h5OSEiIgICARl1wQ8jE9H11WndRbT8RkddX6PnTGGhIQEnLr2CLNOpZS6bs6Lx8i4dQJm7j4QmFtB+fI50qL2Ijf5GZwGLYB53RZlHu/vqe3R2MVGS9HrP2pHTPTG5cuXERcXR7cI9Mxvv/0GU1NTDBs2jO9QCAAzMzOsX78eZ8+exfr16zXapoGzFTrUd9S4C6GmhAIOHeo7VkmxHcdxcHZ2RsNGb5W5rmnNerDvMh6Shm1h5tYElk27ouaI5RBa2uNl+G8aHU+TURjGiJIBonOhoaFwcHAo9hIi4YdarcbGjRsRFBQEGxvjOUvSdwEBARg7dixmzZpVZJrikgT384FIy8mASMAhuJ+PVvdZFk1GRxRHYGYJ8/qtkJsYDXWuosz1K3qc6o5eFaJzYWFh6Nu3L0Qiuk+nL44fP47o6GgqHNRD3333HczNzTF16lSN1nezl2CRlivkF/dtDDd7iVb3WZb80REV8upud1n1Btyr45CiKBkgOnXv3j3cu3ePGg3pmfXr16NJkybw86MmLPrGzs4Oq1evRmhoKEJDi/YGKE5QK3fM7NYQQN49+Mr4vJsXBrdyr9Q+KiJ/dER5qbIzkPX4Ekyc6oITmZa6rruDhIoHS0DJANGpsLAwSCQSdO3ale9QyCvx8fHYt28fxo8fX+72tKRqDBw4EH369MHkyZORmpqq0Tbv1FQi7fg6CKEudw2BUMBBLBLg2/4+mBxYvyIha0Wgl1OpsSfuX46Xp7Yg895ZZMfcQPq1w3ixbSZUmSmw6/xRqfvWdHSEsaJkgOhUWFgYevToAXNzc75DIa9s2bIFIpEIw4cP5zsUUgKO47B27Vqkp6dj9uzZZa6vUCgwdOhQOKU/wuGp7eBf1wEAykwK8pf713XA8RkBvFwReN0wP/dSh0ma1vBE1pOrkB1ajfiQr5ByejtMHN1Qc8RymHs2K3XfKjXD8Db8Pj99RtdLiM48e/YMUVFR2L59O9+hkFfUajU2bNiAQYMGwc7Oju9wSCnc3NywdOlSTJ06FcOGDSu24U++r776Crdv30ZUVBQaujpg+xgHPIxPx84oKcIfJEAqkxfqVMgh75J5YEMnDG/jrjctevNHR0Q+Kb75kE3bQbBpO6jc+xUKOPjXddCb56mPqM8A0Zl169Zh6tSpSExMpC8ePXHixAl06dIFZ86cKfXLhegHlUqF9u3bIyUlBdeuXSu2VfHx48fRtWtXLF++HDNnzix2P5kKJaJlmchRqmEqEsDTwUJv753HJsvRZWUEFFocAigWCXB8RkCVF0XqA+ozQHgXGhqKTp06USKgRzZs2IBGjRrRME8Dkd+q+PHjx1i6dGmR5TKZDCNHjsQ777yDTz/9tMT9WIhFaOxig+budmjsYqO3iQBQfUZHGBpKBohOpKSkIDw8nBoN6ZHExETs3buXCgcNTJMmTTBr1iwEBwfjzp07BY8zxjB27FgoFAps3bpVo46FhuL10RGVxdfoCENTfd49RK8cPHgQSqUS7733Ht+hkFe2bt0KjuMwYsQIvkMh5fTll1+ibt26GDduHNTqvMvnGzduRFhYGDZu3AhXV1eeI9S+KYENsKy/D8QiQblHRwjA9GJ0hCGhmgGiE4MGDUJMTAwuXrzIdygEeWeR3t7eaNmyJXbu3Ml3OKQCTp8+jYCAAKxduxbvvPMO3n77bQwbNkzj1sWGKjZZjrmhN3HmUVKZ0xvnLzdJeoQTy8bCnRoMafz9TckA0brs7Gw4Ojpi7ty5mDt3Lt/hEAARERHo1KkTTp06hYCAAL7DIRU0YcIE7Nq1C3Xq1IFCocDVq1dhYWEcX3iajo6oj+cY8V5XHDhwAL169eIrXL1ByQDhzYEDB9CnTx/cuXNH46lYiXaUVDU+bNgwXL58Gffu3aN6AQOWkpKC2rVrQy6X4+LFi0Y79XRpoyMYY+jYsSMUCgWioqKM/v2u6fe3/paUEoMVFhaGhg0bwtvbm+9QjELBGdP9BEiTi54xudqIcV9mg3EfTjb6D0ZDd/XqVcjlcjDGEBMTY7TJQP7oiOJwHIf58+ejW7duOHz4MHr27FnF0RkmujJAtEqlUqFWrVr46KOPsGzZMr7DqdbKcy+VqVXgBEJ0qO+I4H4+NMzKAMlkMvj6+qJhw4awsrLCxYsXcffuXdja2vIdmt5hjKFdu3ZQq9U4f/68USfB1GeA8CIyMhKJiYk0MZGOhVySosvKCEQ+kQFAqYkAAHACIQAg8okMXVZGIOSSVOcxEu1hjGHChAmQy+XYtm0bfv75Z2RmZmLWrFl8h6aXOI7DggULEBUVhaNHj/IdjkGgZIBoVVhYGGrVqoXWrVvzHUq1tSb8IWbvvQmFUl1mEvAmlZpBoVRj9t6bWBP+UEcREm3bvHkz/vzzT2zYsAG1a9eGq6srli1bhvXr1+P06dN8h6eXunXrBj8/PyxatKjSMzkaA0oGiNYwxhAaGor33nuvWjVA0Schl6RYcfSBVva14ugD/E5XCPTegwcPMG3aNIwZMwYDBgwoeHzixInw9/fH+PHjkZ2dzWOE+in/6sD58+dx4sQJvsPRe/SJTbTm5s2bePr0Kd0i0JHYZDkW7L+t1X3O338bsclyre6TaE9OTg6GDRsGV1dXrFq1qtAygUCADRs24MmTJwgODuYnQD3Xo0cPtGrViq4OaICSAaI1oaGhsLa2RmBgIN+hVEtzQ29CWcptgZwXj5Hw59f4d81ISFcMwLP1E5FydjfUuSWfNSrVDHNDb+oiXKIFCxcuxLVr17Bz505YWloWWf7WW29hzpw5WLZsGW7dusVDhPot/+rA2bNnER4eznc4eo1GExCtad68ORo1aoRdu3bxHUq18zA+HV1XlXxvOCdJihdbpkNk7wqbth9AYG4NRewtpEb+DvN6reA0cF6p+z8+oyNN76pnTp06hc6dO+Obb77BnDlzSlxPoVCgWbNmsLW1xdmzZyEUCqswSv3HGEPr1q0hkUgQERHBdzhVjkYTkCr19OlTXLt2jSYm0pGdUdJS+7Nn3okAU+agRr+5sGjUAeaevrDtMAyWvt2Q9SgKquyMErcVCjjsuEC1A/okOTkZI0aMQMeOHfHFF1+Uuq5YLMaGDRtw4cIFrFu3rooiNBz5fQdOnz6NU6dO8R2O3qJkgGjFvn37IBaL0aNHD75DqZbC7yeUOnIgf+igQFy4f4BAbAFwAnCCkvuLqdQM4Q8StBMoqbT8YYQZGRnYvn27Rmf67du3x8SJEzFnzhzExsZWQZSGpXfv3mjevDkWLVrEdyh6i5IBohVhYWHo0qULrKzoUrO2ZSiUkJZR5GfZ5B0IxBZIPvIzclNeQK2QQ/7oItKvHYbV270gMDUrdXupTI5MhVKbYZMK2rJlC/bs2YP169fDzc1N4+2WLVsGa2trTJ48mYrl3pB/deDUqVM0FLMElAyQSktMTMSZM2doFIGOxMgyUdZHu8jWGTVHrkBOUgzifhmL2JUfIHHPYlg26Qy7LuPLPAYDEC3L1Eq8pOIePXqEqVOnYvTo0Rg0aFC5trWxscGaNWvw119/Yc+ePTqK0HC999578PX1pasDJaBkgFTagQMHwBhDnz59+A6lWspRqstcR5kSj4Q9iyE0t4bj+3PgPHQZbAM/RMatE5Ad+klrxyG6k5ubi6FDh6JmzZr46SfNfmdv6tevH/r164epU6fi5cuXWo7QsOVfHTh58iTOnj3Ldzh6h5IBUi6ZCiVux6XiH+lL3I5LRaZCidDQULRr1w7Ozs58h1ctmYrK/jN9GbEFakUWnD5YDAvvdjBzbwIbvwGwf2ccMm8cQ7a07OGDmhyH6M6iRYtw9epV7Ny5s1K329asWYOsrKwyCw+N0fvvvw8fHx+6OlAMmrWQlKmsWfFyXfvi7RZiPIxPRwNnqhnQNk8HC3BAqbcKcuKfwsTRrUhtgGmtBgCA3MQYmLn7lLg99+o4hB+nT59GcHAwlixZAj8/v0rty8XFBd9++y0+/vhjDB8+HAEBAVqK0vAJBALMnz8fgwYNQmRkJPz9/fkOSW/QqQApUWyyHCM2RaHrqtPYHhWDmDcSASDvC0pkWwu3FPbouuo0RmyKoo52WvbkwV1YIKvUdYSW9shNkkKdU3g9xbN7ecutHEvd3t1BUjAfPKlaKSkpGD58ONq3b4/Zs2drZZ/jx49H+/btqVVxMfr3748mTZpg8eLFfIeiVygZIMUq76x4+YtpVjztePr0KYKDg9GkSRM0bdoUybfOgGMl39O3bvUe1PI0xId8hcy7Z5AVfR2pkX/g5clNMHF0h3m9FiVuKxRwCGzopIunQcrAGMPEiRORlpaGHTt2aK1hkEAgwPr16xEdHY2vv/5aK/usLgQCAebNm4cjR44gKiqK73D0BnUgJEWsCX+olclwZnZriCmBDbQQkXGIj4/H//73P+zatQvnz5+HRCLB+++/j6FDh6KOb1u8u/Z8qdtnx9xA6oX/ITchGmqFHEJrR0jqt4Z120EQmpf+d0sdCPmxbds2jBo1CiEhIRg8eLDW979o0SJ8/fXXuHLlCpo2bar1/RsqtVoNHx8feHh44ODBg3yHo1Oafn9TMkAKCbkkxey92utV/21/Hwxu5a61/WlLpkKJaFkmcpRqmIoE8HSw4OUyeVpaGkJDQ7Fr1y6cOHECHMehR48eGDp0KPr27QsLi//u44/YFIXIJ7JyT1tcGqGAg39dB2wfU7n71KT8Hj9+jGbNmqF///7YunWrTo6hUCjQvHlzWFlZITIykloVv2b37t0YOnQooqKiqvWU65QMkHKLTZajy8oIKLQ4xEwsEuD4jAC42UvKXlnHyiqEdLeXINDLCcP83HVaCJmdnY1Dhw5h165dOHDgALKzsxEQEIChQ4diwIABcHBwKHY7rf9+GIOpSIATn3bSi9+PMcnNzUWHDh2QmJiIf/75R6efq+fOnUP79u3x448/Ytq0aTo7jqFRqVRo0qQJ6tWrhwMHDvAdjs5QMkDKLf/MMzcrE6mRIciJf4qc+MdQZ6XBpt0Q2HYYVrAuU6uQfnk/sp7+g9ykGKizMiC0qQFJgzawaTMQArO8Gdb04cwzNlmOuaE3ceZREoQCrtQz6/zlHeo7Irifj9a+JFUqFU6dOoVdu3bhzz//RGpqKpo3b46hQ4di8ODBGnea0/aVm5wzv2Hviplo06aN1vZJyjZ//nwEBwfj7NmzVfLaT5o0Cdu2bcOdO3fg7q5/V+r4snPnTgwfPhyXLl1Cy5Yt+Q5HJ2iiIlIuD+PTceZRElRqBnVWOtKvHQFT5ULSsPgPKqbMQcrZXRDZOMHunXFwGrQAVr7dkXHtMF7s+ALqXAWAvMLDM4+S8CghvSqfToHyFkLmL9dGISRjDBcvXsSMGTNQu3ZtdOnSBREREZg2bRru3LmDq1evYubMmeVqORvUyh0zuzWscEyv+7idK+riBTp16kQzTVahs2fP4ptvvsGCBQuqLAlbunQpbG1tMWnSJGpV/JqgoCA0bNiQRhaArgyQVxbuv43tUTFQqVnBhwXHcVDJU/HvT8OKvTKgVmQWKUzLvHcWSWHL4ND7M1g2CQSQd7Y9ws8DC/s2rronBP4KIe/du4ddu3Zh165dePz4MWrWrInBgwdj6NChaNWqFTiu5NkHNRVySYoF+29DqWblqiEQCjiIBBwW922Mwa3coVAoMG7cOGzfvh3z5s3DwoULIRDQOYKupKSkoFmzZqhduzZOnToFkajq6lT27duH999/X2fFioZq+/btGDlyJK5cuYK3336b73C0jq4MkHJ5fVY8juPK/MLiBMJiK9TFtfLOWlXpiQWP8TErXsglqVYSAQBYcfQBfi/jCkFsbCxWrFiBt99+G40aNcJPP/2EgIAAHD9+HP/++y9WrVqF1q1bayURAPKuEByfEQD/unn1BaVNb/z6cv+6Djg+I6CgqFMsFmPr1q0FDW+CgoIgl1OfCF2ZPHkyXr58iR07dlRpIgDk9eYfMGAApk2bhuTk5Co9tj4bMmQI6tevb/RXBygZIBrNiqep7JgbAAATR49Cj1flrHixyXIs2H9bq/ucv/92kWZKMpkMv/76KwICAuDu7o6vvvoK9erVw969e/HixQts2rQJ77zzjs4quN3sJdg+xg/HpnfECD8PeDhI8GZKwAHwcJBghJ8Hjs/oiO1j/IrUQXAchzlz5uDPP//E33//jYCAAMTFxekkZmO2Y8cO7Nq1C+vWrYOnpycvMaxevRoKhQKff/45L8fXRyKRCF999RX27duHa9eu8R0Ob+g2AcHtuFT0Wl38xB0l3SYojjI9Cc+3TIfIqgZqjvoeHFc41/x7ans0drHRWtwlKU8hJACkXd6PzDsRUL58DnWOHEILO4hdvWHjHwTTGnlJTX4h5C9BTbB//37s2rULhw8fhlqtRpcuXTB06FD069eP97+Pyg6ZvHr1Kvr27QsA2L9/f7W8bMqHp0+fwtfXF++99x62b9/Oayzr16/HhAkTcPLkSQQGBvIai75QKpXw9vZG06ZNsXfvXr7D0Sq6TUA0po3Z6lRZ6Uj4YyHAAMf3ZxVJBADg37gXyM3NrfSxSlPeQkgAUGelw7xuCzj0nArnwUtg234ocuKf4MW2z5Ar+xfAf4WQtbzyRgDIZDKsXLkScXFxOHLkCEaNGsV7IgAAFmIRGrvYoLm7HRq72JS7d8Lbb7+NixcvolatWujQoUO1+2DUtuIm7nqTUqnEsGHD4ODggDVr1vAQZWFjx45Fhw4dMH78eGRlld7m2liIRCJ8+eWXCA0NxY0bN/gOhxfUjJxUerY6VXYGEkK+giojGc5DvoGJbc1i1+vTqyeUidFwcnKCi4sLXFxc4OrqWvD/r/+rUaNGhQrZdkZJC4YHCm2c4DY9pKAQMuP60WK3KXLFw90HYhdvxG38GJm3T8G24/C8x9UqdPhoLlaP7oi6deuWOzZD4eLigoiICIwePRoDBgxAcHAwZs+erbV6B0NX3n4V33zzDaKionDmzBnY2Oj+ylhZ8lsV+/r6YsmSJQgODi60XF8aclW14cOHY8mSJViyZAn+97//8R1Olav+v2FSJk1mxSuJKjsDCbu/hDI1Hs5B38DUqU6J64ZsXI3k+OeIi4sr+HflyhXs378f8fHxhYY8iUQi1KpVq9hE4fUEwtbWttCX1JuFkBUlkLw6yxe8dr9fIESGtUe1TgTySSQShISEwNvbG3PnzsW9e/ewfv16iMVivkPjjSb9KhiAmGQ5tkfFYMv5aPg4inDkx18xb948vZohz9vbG1999RUWLVqEwYMHQ1Kzrl405OKTiYkJ5s6di3HjxuHWrVto0qQJ3yFVKUoGCCzEIrjbSxBTziLCgkQg5QWcgr6Gac16Ja7r4SBB/z4l359UKpWIj48vlCjExcXh2bNniIuLw+nTpxEXFweZTFZoOzMzs4LEoGZtD8R4BAEVTAKYWgWo1VCmvsDLU1shkNjCsmmXQuvkF0Iaw5mSQCDA4sWL4e3tjY8++giPHz9GaGgoatSowXdoVe71oZyA5v0qbiYo4DL2ZzTo0UzXIZbbrFmzsHv/UQxcG4Fch381TnC03ZBLn4wcORJff/01lixZgt9//53vcKpU9f9EIxoJ9HIq6DMAAFmPL0Odmw32akrcXFksMu/lFRma12sJgEPC7/OQE/8Edl3GAWpVwXS5ACCQ2MDErhYAzWbFE4lEcHV1haura6nrZWdn48WLFwVJwuv/nqbkVjgRAADp9wMBVV5Ng8jeFTWHLoXIuvAXHwMQLcuskkJIfTF06FDUqVMH77//Plq3bo2//vrLqM6aKtWvQiAEIMSX+27jZVauXk3ctff6C+R2m42cXCU4lL8h16K+jRGkh/OOVIapqSnmzp2LiRMnYsGCBXjrrbf4DqnK0GgCAiDvPmjXVacLfv7354+gSiu+N4DrxE0AgGe/jClxfxZN3oFj7xkFP1fFrHj/SF+i37rIYpdpMipC8eIRoFIiN+U50i/tgzI9Ke/WR43CwyRDP/ZHc3c7rcev72JiYtCnTx9ER0cjJCQE7777Lt8h6Vx1nbiLZiYtWU5ODho0aAB/f3/s3r2b73AqTdPvb7oyQAAADZyt0KG+Y8GseLUnbS5zG4/ZZU/ukT8kryqmx61sIaS4Zv28/7p6Q1LfD89+HY+UiG1wGjhPq8cxVB4eHjh37hyGDh2KPn364Pvvv8cnn3xSbQsLddWvwr+eI6+X2LXdkKuGpVgvEhxtMTU1xZw5czBp0iTMnz8fjRo14jukKmGcn2qkWMH9fCAqo5NdeYkEHIL7+Wh1nyXJL4TUBoFYAhOH2sh9+azQ49yr4xgrKysrhIWF4dNPP8WMGTMwceJEnQ8X5cvc0JsFNQIlyY69jfg/FiB25WBIV/THs1/HIeVcyWeTSjXD3FDtXWkor9ISnKzo60j6exWerZ8I6fcD8O+akUjYsyTvilkpimvIZeg+/PBDuLq64uuvv+Y7lCpDyQAp4GYvwSItzx+wuG/jKjsLyi+E1AaVPBW5idEwsa1V6HF3B4lRFA+WRigUYvny5di4cSM2b96MHj16VLv2tq/3qyhJ5u1TiN81BwKxBRx6fwqnQQth3WZgqcNy+J64q7QEJ+Ofg1CmJsC6ZV84DVoIuy7joZKn4MW2z5AVfb3EffKd4OiCWCzGnDlzEBISgvv37/MdTpUw7k81UkRQK3ckZSheXUZkQCXOtT/v5lXllw/LXQipUiH+969g8VYniOxcwIlMoXz5DGmX94OpcmHTfmjBvjUphDQmY8aMQf369dG/f3+0adMGBw4cQMOG2plRkW+v96sojjI9CbLDa2DZrAccuk8qeNzMo2mZ+xYKOOy4IK3yibvyE5yS2Hf7GEIL20KPmddtgWe/jkPa+T9g7ulb7HavJzhVcTuwqowZMwbBwcH4+uuvC3WNrK59GAz/GRCtmxLYAGZQYsnBe+CEIqCYboIleXNWvKo2zM8dW85HF/wsO/JzoUJI+b2zkL9KBlwnboLQ0h6mTnWQce0wlOlJYMocCC3sYObuA+t+c2Hq+N9zUKkZhrepPvdGtSEgIABRUVHo06cP2rRpgz179qBz5858h1Vpr/erKE7G9aNgudmwaTOw3PvOn7hrIao2GSgrwXkzEQAAgak5TBzcoUwvOYkA+EtwdEksFmPWrFmYPn06Rk2dhbMvuGrdh4GSAVKsi7tXIv1QOLrM3YSL0vRSP0QAFCz3r+vA6xjkihRCOvScVuY6VVkIaWjq16+P8+fP44MPPkD37t2xdu1ajB8/XuPt9e1MS5OJuxSxtyAws0KuLBYJfy5BbmIMBOZWkDRsC7vAjyAQl/7+56NfRVkJTnHU2ZnIiX9c5hUPvhIcXes5cDiWX8rC2NCYat+HgZIBUkRUVBQ2btyI1atXY/LHHf9rv/ogAVJZMVmxgwSBDZ0wvI27XnxZBvfzQZeVEeX+4CtNVRZCGiJbW1scPHgQn3zyCSZMmIA7d+7g+++/L3HGxvK29K1KMbLMMrtxKtOTwZQKJIYtg03bQRC/Mw6KFw+RemYXcpOkcB72bamjLKq6X0VFZyZNPrYu7wqI/+Ay161uDbnyG00JXd8CQ/Xvw1A9fmtEa1QqFSZNmoRmzZph4sSJAPLOthf2bYyFaKx3Z3HFyS+E1Ob48KoshDRUIpEIa9euxVtvvYVPPvkEDx48QEhISKGxzRVp6VvVZ1oaTdzF1GDKHNgGjIJN20EA8uoFOIEIL09sQHbMdZh7Nqv8cbREkwTnTSmntyPz9inYdZ1QMOy2NNWpIVfhPgzlq5tSqRlUaobZe28iKUNhMH0YaDQBKeTXX3/F1atX8fPPPxd7VlfZWfGqSlArd8zspp1iNj4KIQ3Z5MmTcfDgQZw7dw7+/v54+vQpgLwzrS4rIxD5JK+ldHnPtEIuSXUb+Cua9JEQmOddrTCvU3iK57zunEBOGcPxND2OtpQ38Ug5uwupkb/DtuNIWLfoo7Pj6CNt92H4vYret5Wln5/khBcJCQn48ssvMXbsWLRpU/KUv4ZiSmADOFqKC3rKl+e2Ad+FkIauW7duuHDhAnr37o3WrVtj9PIQ/O9+doX2VRVnWnK5HJcuXcL58+dxLuoymNfoUi/zmzrVQU5cMUPO8hu6llF0W9X9KsqTeKSc3YXUs7tg034obPw/0Nlx9FFZjabUOVlIOb0d8ntnocpKh4lDbdi0GQiLtwJK3EYfGk1pgpIBUuCLL76AQCDA0qVL+Q5Fa4JauaNdPccyL03n05dCyOqgUaNGiIqKQrePF1U4EXiTNjreMcbw9OlTnD9/vuDf9evXoVKpYGlpidatW8OKUyADZiXuQ+Llj4xrh5H15EqhCbqyHl8GAIhdvEqNoar7VWg6M2nKud15iYD/YNi+NqxWE9WhIVdZjaYS9wYj5/kD2HYaDRN7V2TeOYWk/csBxmDRuFOx2+T3Ydg+xk9HUWsHJQMEAHD27Fls3boV69evh6OjI9/haJWbvQTbx/gZXCFkdZAlkCDT+10gV1VkEqmkAyuReetEidvWHLECYlfvIo+X90xLLpfj8uXLBV/8Fy5cQHx8PACgYcOGaNu2LcaNG4e2bduiSZMmEAqFWLj/dqF+FW8yr/M2zOu3Rsq53WBMDbGrN3KeP0Tqud0wr9cKZm4lV9Xz0a9Ck5lJ06L2IvXMTpjVbQHzeq0KTTwGoNjfxesMvSFXWX0Ysh5fQnb0P3Ds+3nBlQAzj6ZQpibiZfhmSBp1ACcoemvVUPowGO5vjmiNUqnEpEmT0Lp1a4wZU/LkQ4bO0Aohq4OCM61iLrnbtAuCVfOeRR5P2LMYnMgEprWKvx1Q2pkWYwzR0dFFzvqVSmXBWf/YsWPRtm1btGnTBg4ODsUe481+FcVxfG8WUs/tRsb1I0g9txtCS3tYtXoPtu1KP6Pmq1/Fmw253iR/dBEAkP3kCl48uVJkeWlzkVSHhlxl9WGQPzgPztQcEu/2hR63bNoFSfuXQxH3AGa1i5/HwBD6MNCnH8GaNWtw69YtXLp0CQKBYd/z01R+ISTRnbLOtEzsagF2hds9Z0tvQp2VBhv/wcWeZQGFz7RcrUSFzvrPnz9fcNbfoEEDtG3btuDLP/+sXxNv9qsojsBEDLtOo2HXabRG+wT47VdRVoJTc9iyCu+7OjTkKqsPQ05iDEwcahd5X5rU8AQA5CbFlJgMGEIfBkoGjFxcXBzmz5+Pjz/+GC1atOA7HFKNlHWmVZyM60cBcLBo2rXU9TimRp8Zy/Hoj6VQKpWwsLAouLKVf9Zf2dtd1a1fhSYJTkVUh4ZcmvRhUGelQ2Rbs8jj+SNL1FlppW6v730Y9DMqUmVmzpwJMzMzo5qdi1SN8na8U2dnQn4/EmaevjAp5kP3dYwTgLm8hZ9++qngrF8k0u7HWXXsV1HdEhxt0bgPQ6nTdZfej0Df+zAYxzVhUqyTJ09i9+7dWL58Oezs7PgOh1QjFel4l3k3AkypgGUZVwXyKURWGPnRODRr1kzriUC+6tavwtBnJtUVTfojCMytij37V2elFyzXxnH4QsmAkcrJycHkyZPRvn17jBw5ku9wSDVTkY53GdePQWBuDUlDf43Wzz/T0rUpgQ2wrL8PxCIBhILydaMTCjiIRQJ8298HkwPL7uJXFbSZ4LyM2IoXkaFa2RefNOmPYFrDE7myf8HUqkKP5yZGAwBMHD20chy+6G9kRKdWrlyJhw8fYu3ataU2VyGkIsp7BpST8BQ5Lx7ConEncCITnR2nooJaueP4jAD4180bfVBWUpC/3L+uA47PCOD9isCbtJXgTGjvienTp2PHjh06irRq5PdhKI2kYVuwnCzI758r9HjGrZMQWtpD7FJ6gqXvfRioZsAIxcbGYvHixZg6dSqaNi17/nVCyqu8Z0B5hYOApW83nR6nMqpbvwptNOT6oOW3SEpKwocffgg7Ozv06tWrCp+B9mjSh8G8XkuYeTZH8pGfoVbIYWLngsw7Ech+cgUOfT4rcfRLPn3vw6C/kRGdmTFjBmxsbLBo0SK+QyHVlKYd7wCAKXORefsUTGs1hOmrYVqa4OtMqzr1q6hsgsNxHNavX4/k5GQMGjQIx44dQ7t27ar8eWhDWX0YAKBG/7lIidiG1DM7ocpOh4l97UJNiEpiCH0YDOddS7TiyJEj+PPPP7Fr165Cs8kRok2anGnlkz88D3V2Oix9R5XrGPpwplVd+lVUJsERiUTYvXs3evbsid69eyMiIsIgrzhq0mhKYGoO+64TYN91Qrn2bQh9GKhmwIhkZ2djypQpCAwMRFBQEN/hkGou0MtJo/vRGdePgTMxg0Wjjhrv2xDOtAxVRWYmNTc3x759++Dp6Ynu3bvjyZMnVRCpduX3YShvDUVZhAIOHeo76vUtI4CSAaOyfPlyREdHU9EgqRLD/Nw1Gs/uHLQE7p/tgUCs+fA0QzjTMjY2NjY4fPgwLC0t0a1bN7x48YLvkMotuJ8PRFpOBgylDwMlA0bi6dOnCA4OxqeffopGjYpvmUmINhn7mZYxcnZ2xrFjxyCXy9GjRw+kpKTwHVK5GHMfBkoGjMQnn3wCR0dHzJs3j+9QiBEx5jMtY+Xp6YmjR48iJiYGffv2RVZWFt8hlUtQK3d84PVq+mpWuU6N+tBoSlOUDBiBv/76C3/99RdWrVoFS0tLvsMhRsSYz7SMWZMmTfD333/j8uXLGDx4MJRKJd8haUwmk2H3vNGwffA3xCbCatFoShOUDFRzcrkc06ZNQ/fu3dG/f3++wyFGqLq19CWa8ff3x59//olDhw5h7NixUKv1txVvPrVajZEjRyIrKwt/rZpTrRpNlYWGFlZzS5cuRVxcHI4ePUpFg4Q3UwIbwNFSjAX7b0OpZuWaKEco4CAScFjct7HBfcAau549e2Lr1q0YNmwYHB0dsXz5cr3+HFqxYgUOHjyIgwcPws3NDQCqVaOp0nCMlX1TJC0tDTY2NkhNTaWx6Qbk4cOHaNKkCWbNmoXFixfzHQ4hiE2Wl7vjXYf6jgUd74hhWr16NaZNm4Zly5Zh1qxZfIdTrLNnz6JTp074/PPPsXTp0hLXM7RGU5p+f1MyUE0xxtCjRw88ePAAt2/fhkRCH6REfxjDmRYpbMGCBVi8eDE2bNiAsWPH8h1OIUlJSWjWrBnq1KmD8PBwnc2CyQdNv7+rzzMmhezduxdHjx7F/v37KREgeqc6tfQlmlm4cCGSkpIwYcIE2Nvb600Nk1qtxogRI6BQKBASElKtEoHyMM5nXc1lZGRg+vTp6NOnD/r06cN3OISUqrq09CWl4zgOP/30E2QyGYYMGYJDhw6hc+fOfIeF7777DocPH8bhw4fh6urKdzi8odEE1dCSJUuQlJSEH3/8ke9QCCGkgFAoxLZt29CpUye89957uHz5Mq/xnDlzBl999RXmzp2L7t278xoL36hmoJq5c+cOfH19sWDBAnz11Vd8h0MIIUVkZGSgS5cuePz4Mc6ePQsvL68qjyExMRHNmjVD/fr1ceLEiWp7e4AKCI0QYwydO3fGv//+i1u3bkEsFvMdEiGEFEsmk6FDhw7IzMzEuXPnULt27So7tlqtxrvvvourV6/i2rVrcHFxqbJjVzVNv7/pNkE1snv3bpw6dQpr1qyhRIAQotccHBxw9OhRAED37t0hk8mq7NjLli3D0aNHsWPHjmqdCJQHJQPVRFpaGj777DMMGDDA6O99EUIMQ+3atXH06FEkJCSgV69eyMjI0PkxIyIiMG/ePHz55Zfo1q2bzo9nKCgZqCYWLFiA9PR0rFy5ku9QCCFEY15eXjh8+DBu376NAQMGICcnR2fHSkhIwJAhQ9CxY0csXLhQZ8cxRJQMVAM3btzA6tWrMX/+/IIWmoQQYihatGiBffv24dSpUxg5ciRUKpXWj6FSqTB8+HCoVCrs2rULQqFQ68cwZNWzfNKIqNVqTJo0CQ0bNsT06dP5DocQQiqkc+fO2L17NwYNGgQHBwesWbNGq/MYLF26FMePH8fRo0dRq1Ytre23uqBkwMBt27YN586dw8mTJ2Fqasp3OIQQUmH9+/fHL7/8gvHjx8PR0RGLFi0qdX1Nu1eGh4djwYIFmDdvHrp06aKr8A0aJQMG7OXLl/jiiy8wZMgQBAYG8h0OIYRU2rhx4yCTyTBnzhw4Ojpi6tSphZYXzGtxPwHS5GLmtbCXINDLCcP83NHA2Qrx8fEYOnQoOnXqhPnz51fpczEklAwYsK+++grZ2dn4/vvv+Q6FEEK0ZtasWUhMTMS0adPg4OCAoUOHajTjJQMQkyzH9qgYbDkfjfb1HBC79zswxrBz506qEygFJQMG6sqVK1i3bh1++OEHuv9FCKlWOI7D8uXLIZPJMGrUKNzOtsWepxyUrxKA0qa+fn35ucdJUL01HBODJqJmzZo6j9uQUQdCA6RWq9G2bVtkZ2fjypUr1baNJiHEuCmVSrQbvwTxzq0rsRcGgMPMbg0xJbCBtkIzGDSFcTW2ceNGXLx4EWfPnqVEgBBSbe35J66SiQCQV0kArDj6ADUsxRjcyr3ygVVD1GfAwCQlJWHOnDkYPXo02rVrx3c4hBCiE7HJcizYf1ur+5y//zZik+Va3Wd1QaeVBmbOnDlQq9X49ttv+Q6FEEJ0Zm7ozYIageKoFXKkRoYgJ/4pcuIfQ52VBpt2Q2DbYViJ2yjVDHNDb2L7GD9dhGzQ6MqAAblw4QI2btyIb775Bk5OTnyHQwghOvEwPh1nHiWVWiiozkpH+rUjYKpcSBq20Wi/KjXDmUdJeJSQrq1Qqw1KBgyESqXCpEmT0KJFC0yYMIHvcAghRGd2RkkhFJTefVBo4wS36SGoOWwZbANGabxvoYDDjgvSyoZY7VAyYCDWrVuHa9eu4eeff6axsoSQai38fkKZwwc5jqtQu2KVmiH8QUJFQ6u2KBkwAPHx8fjqq68wbtw4tG5d2cpaQgjRXxkKJaQ6LvKTyuTIVCh1egxDQ8mAAfj8888hEokQHBzMdyiEEKJTMbJMlNn8ppIYgGhZpo6PYlhoNIGeO336NLZv344NGzbAwcGB73AIIUSncpTqanUcQ0FXBvRYbm4uJk+ejDZt2uCjjz7iOxxCCNE5U1HVfC1V1XEMBV0Z0GOrV6/GnTt3cPnyZQgE9MYlhFR/ng4W4ACd3irgXh2H/Ie+YfTUs2fPsGDBAkyaNAnNmzfnOxxCCKkSFmIR3O0lOj2Gu4MEFmI6F34dvRp66rPPPoNEIsGSJUv4DoUQQqpUoJcTtkfFlDm8MOvxZahzs8FysgAAubJYZN47CwAwr9cSAhOzItsIBRwCG1LTtjdRMqCHTpw4gd9//x1bt26Fra0t3+EQQkiVGubnji3no8tcT3bkZ6jS/usZIL93FvJXyYDrxE0Q2BZNBlRqhuFtaLKiN9EUxnomJycHTZs2hZOTEyIiIirUVIMQQgzdiE1RiHwiK/PqQHkIBRz86zoY1dwEmn5/U81AFctUKHE7LhX/SF/idlxqkcYXP/zwAx49eoS1a9dSIkAIMVrB/XwgKqMlcXmJBByC+/lodZ/VBd0mqAIP49OxM0qK8PsJkCbLC1XJcgDc7SUI9HJCZ3cTLFmyBJ988gl8fOgNSwgxXm72Eizq2xiz997U2j4X920MNx0XJxoquk2gQ7HJcswNvYkzj5IgFHClXu7KX66Ou40jX49GIzcqcCGEkDXhD7Hi6INK7+fzbl6YHFhfCxEZFrpNwLOQS1J0WRmByCcyACjzvlf+cpHLW3h//RWEXKJZtQghZEpgAyzr7wOxSFDmTIZvEgo4iEUCfNvfxygTgfKgZEAH1oQ/xOy9N6FQqstd/KIGB4VSjdl7b2JN+EMdRUgIIYYjqJU7js8IgH/dvJbsZU5v/Gq5f10HHJ8RgMGtaPRAWahmQMtCLkm1ckkLAFYcfYAalmJ6IxNCjJ6bvQTbx/j9V4P1IAFSWTE1WA4SBDZ0wvA27qjvZMVXuAaHaga0KDZZji4rI6DQ4gQYYpEAx2cEUNELIYS8IVOhRLQsEzlKNUxFAng6WFBnwTdo+v1Nr5oWzQ29CaWaQa2QIzUyBDnxT5ET/xjqrDTYtBsC2w7DStyWMYb4nbOh+Pc2rN7uBftuHwMAlGqGuaE3jWpcLCGEaMJCLEJjFxu+w6gWqGZASx7Gp+PMo6S8EQFZ6Ui/dgRMlQtJwzYabZ9+9QCUKc+LPK5SM5x5lIRHCenaDpkQQggBQMmA1uyMkhYUrQhtnOA2PQQ1hy2DbcCoMrdVpsQjJWIb7LtOLHa5UMBhxwUaXUAIIUQ3KBnQkvD7CQUjBziOK1f3QNnhNTDzbAaJl3+xy1VqhvAHCcUuI4QQQiqLkgEtyFAoIU2WV2jb9OtHoHj+oMSrAvmkMnmR1sWEEEKINlAyoAUxskxUZCoNZXoSXp7cDLvADyGycih1XQYgWpZZofgIIYSQ0lAyoAU5FRxKmHx4LUyd6sDSt7tOj0MIIYSUhpIBLTAVlf9lzLx3FllPr8Iu8EMwRSbU2RlQZ2cAAJhKCXV2Bpiq8G2BihyHEEIIKQv1GdACTwcLcEC5bhXkJsYAahVebPusyLKM60eQcf0IavT/EpKGbQHkddbydLDQSryEEELI66pVMsBXNyoTTg17sRoyheZn7pY+XWDmXnSa4vjdc2HeoA2sW/aFSQ2PgsfdHSTUWYsQQohOGPy3S0Gf6vsJkCYX06faXoJALycM83NHA2ft9qm+desWNm/ejO3bt0PVrD+s3+4FCIQAgKzHl6HOzQbLyQIA5MpikXnvLADAvF5LiGydIbJ1Lna/IisHmHk0LfhZKOAQ2JCmNCaEEKIbBpsMxCbLMTf0Js48SoJQwBU7OyADEJMsx/aoGGw5H40O9R0R3M+nUn3+U1JSEBISgs2bN+PSpUuoUaMGRo4ciXf6D8OkA/91EJQd+RmqtP96A8jvnYX8VTLgOnETBLZmGh9TpWYY3oYmKyKEEKIbBjlRUcglKRbsvw2lmpVrimChgINIwGFR38YIKsdMgGq1GhEREdi8eTP27NmDnJwcvPvuu/joo4/Qq1cvmJqaAgBGbIpC5BNZuactLitm/7oONDcBIYSQcqu2ExWtCX9Y4SmCVa+Sh9l7byIpQ4EpgQ1KXV8qlWLr1q347bff8PTpUzRo0AALFizAyJEj4eLiUmT94H4+6LIyQqvJgEjAIbhf0doCQgghRFsMKhkIuSStcCLwphVHH6CGpRiD37hCoFAosG/fPmzatAnHjh2DRCLBBx98gG3btqFdu3althl2s5dgUd/GmL33plZiBIDFfRvT9MWEEEJ0ymCSgdhkORbsv63x9MBJB1Yi89aJIvsR2deG6/hfAADz99+Gfz1HuNlLcO3aNWzevBk7d+5EcnIy/P39sXHjRgwaNAhWVpoXHga1ckdShkIrScvn3byKJCuEEEKIthlMMjA39CaUr00PbOpUB5KGbZBx/WiJ23AiMZyHfPPGY6YF/69UqTH8p7+Rvn8p/vnnHzg7O2Ps2LH48MMP4e3tXeFYpwQ2gKOluFJ1DYv7NqZEgBBCSJUwiGTgYXw6zjxKAvDf9MAcx0ElTy01GQDHQexa8pe6igExCgkaNfDF/kWL0KNHD5iYmGgl5qBW7mhXz7HMEQ/58pf713Wo9IgHQgghpDwMIhnYGSUt+LIsz9TAmhBygN+wmejTp7FW9wvk1RBsH+NX0Athb9R9pKpMCz0HDnkNhQIbOmF4G3fUd9JuLwRCCCGkLAaRDITfT6hQhT5T5iB29XCo5WkQWtpB0qANbDoMh9D8vy9cFQPCHyRgIbSfDORr4GyFhX0bI/HIzzhz/iJ2Hzhe5V0SCSGEkJLo/bdQhkIJabK83NuZOtWBqVOdgpa+2bG3kH4pDFkx11Fr1EoITM0L1pXK5MhUKHX+pRwTEwMP15po7GKj0+MQQggh5aH3yUCMLLNcEwDls279fqGfzes0h6lTXSSFLUXGtSOFljMA0bJMnX9JS6VSdOzYUafHIIQQQspL7+fEzVGqtbYviVdbcCZmUMTd1+lxShITEwN3dxohQAghRL/ofTJgKtJ2iAwopghR+8cpLDU1FWlpafDw8Ch7ZUIIIaQK6X0y4OlgAW2NH5DfOweWq4DYxavQ49yr4+iSVCoFALoyQAghRO/ofc2AhVgEd3sJYl4rIixremC1PA1J+5dD0qgjTOxqARyHbOlNpF/eDxNHd1j6di90DHcHSZUUDwKUDBBCCNE/ep8MAECglxO2R8UUDC8sa3pgzswCAgtbpF0KgzozBYypILJ2glWLPrBp+wEEpv9NHywUcAhs6KTz5yCVSmFiYoJatWrp/FiEEEJIeRhEMjDMzx1bzkcX/Fx70uYyt3Hq/6VG+1apGYa30f3ZekxMDGrXrg2BQO/vzBBCCDEyBvHN1MDZCh3qO0Io0HL3QQGHDvUdq6Trn1QqpeJBQggheskgkgEACO7nA5GWkwGRgENwPx+t7rMkNKyQEEKIvjKYZMDNXoJFfbXbMnhx38ZVNiEQXRkghBCirwwmGQDyZgKc2a2hVvb1eTevKpsiODc3F3FxcXRlgBBCiF4yiALC100JbABHSzEW7L8NpZqVawIjoYCDSMBhcd/GVZYIAMC///4LxhglA4QQQvSSQV0ZyBfUyh3HZwTAv64DAJRZWJi/3L+uA47PCKjSRAD4r+EQ3SYghBCijwzuykA+N3sJto/xw8P4dOyMkiL8QQKkMnmhSY045DUUCmzohOFt3Ktk1EBx8hsOubm58XJ8QgghpDQGmwzka+BshYV9G2MhGiNToUS0LBM5SjVMRQJ4OljovLOgJqRSKWrUqAGJpGqKFQkhhJDy4P+bUossxCKdT0NcETSskBBCiD4zyJoBQ0PDCgkhhOgzSgaqAF0ZIIQQos8oGdAxxhhdGSCEEKLXKBnQMZlMhqysLLoyQAghRG9RMqBj+cMKKRkghBCirygZ0DFqOEQIIUTfUTKgYzExMTA3N4ejoyPfoRBCCCHFomRAx6RSKdzd3cFx2p1+mRBCCNEWSgZ0jIYVEkII0XeUDOgYDSskhBCi7ygZ0LH82wSEEEKIvqJkQIeysrKQkJBAyQAhhBC9RsmADsXGxgKgYYWEEEL0GyUDOkQNhwghhBgCSgZ0SCqVguM41K5dm+9QCCGEkBJRMqBDMTExqFWrFkxNTfkOhRBCCCkRJQM6RMMKCSGEGAJKBnSIGg4RQggxBJQM6BBdGSCEEGIIKBnQEbVajdjYWLoyQAghRO9RMqAjL168QG5uLiUDhBBC9B4lAzoilUoBUMMhQggh+o+SAR2hhkOEEEIMBSUDOiKVSmFtbQ1bW1u+QyGEEEJKRcmAjtCwQkIIIYaCkgEdoWGFhBBCDAUlAzoilUrpygAhhBCDQMmAjtBtAkIIIYaCkgEdSEtLQ0pKCt0mIIQQYhAoGdCB/B4DdGWAEEKIIaBkQAeo4RAhhBBDQsmADsTExEAkEqFWrVp8h0IIIYSUiZIBHZBKpahduzaEQiHfoRBCCCFlomRAB2gkASGEEENCyYAOUMMhQgghhoSSAR2ghkOEEEIMCSUDWpabm4tnz55RMkAIIcRgUDKgZXFxcVCr1XSbgBBCiMGgZEDLYmJiAFDDIUIIIYaDkgEto+6DhBBCDA0lA1oWExMDBwcHWFhY8B0KIYQQohFKBrSMhhUSQggxNJQMaBkNKySEEGJoKBnQMuo+SAghxNBQMqBFjDG6TUAIIcTgUDKgRcnJycjMzKQrA4QQQgwKJQNalD+skK4MEEIIMSSUDGgRNRwihBBiiCgZ0CKpVAqxWAwnJye+QyGEEEI0RsmAFuWPJOA4ju9QCCGEEI1RMqAFmQolbsel4k68HDW9WyJToeQ7JEIIIURjIr4DMFQP49OxM0qK8PsJkCbLwQDArTcAoMnCI3C3lyDQywnD/NzRwNmK11gJIYSQ0nCMMVbWSmlpabCxsUFqaiqsra2rIi69FZssx9zQmzjzKAlCAQeVuuSXL395h/qOCO7nAzd7SRVGSgghxNhp+v1NtwnKIeSSFF1WRiDyiQwASk0EXl8e+USGLisjEHJJqvMYCSGEkPKi2wQaWhP+ECuOPqjQtio1g0rNMHvvTSRlKDAlsIGWoyOEEEIqjq4MaCDkkrTCicCbVhx9gN/pCgEhhBA9QlcGyhCbLMeC/behVsiRGhmCnPinyIl/DHVWGmzaDYFth2FFtmEqJdKv/IWMm8ehfPkcEJrA1NENtoFjYFa7Eebvvw3/eo5UQ0AIIUQvUDJQhrmhN6FUM6iz0pF+7QhMnepA0rANMq4fLXZ9plYhce83yP73Dmz8BkDs6g11rgI5Lx6B5WYDAJRqhrmhN7F9jF9VPhVCCCGkWJQMlOJhfDrOPEoCAAhtnOA2PQQcx0ElTy0xGUi/cgBZT66g5vDvIHb1LnhcUr9Vwf+r1AxnHiXhUUI66jvRsENCCCH8opqBUuyMkkIoyOsmyHGcRp0F0y7vh9itcaFEoDhCAYcdF6h2gBBCCP/oykApwu8nlDl88HXKtESoUuMhqd8aLyO2IuP6Maiz0mDiUBvWfgNg6fNOwboqNUP4gwQsRGNdhE4IIYRojJKBEmQolJAmy8u1jSo9r/9Axq0TEFk5wr7bRAjEEmRcOwLZ3yvBVLmwatajYH2pTI5MhRIWYvo1EEII4Q/dJihBjCwTml8TyJPfzJEpc+A0aCEsvNvDvM7bcHx/Nkyd6yH1XEjh9QFEyzK1EzAhhBBSQZQMlCBHqS73NkLzvGJAE/vaENn8N40xx3Ewq/s2VOlJUGWmVPo4hBBCiDZRMlACU1H5XxqRXS1wJuLiF+ZPAfFGEWJFjkMIIYRoE30TlcDTwQJljx0ojBMIYd6gDXJl/0KZEl/wOGMMWU+uQmRbC0KJzX/rvzoOIYQQwieqXCuBhVgEd3sJYl4rIsx6fBnq3GywnCwAQK4sFpn3zgIAzOu1hMDEDLYdhiP78WXE/7EAtu2HQCCWIP36UeQmPIXj+7MKHcPdQULFg4QQQnhH30SlCPRywvaomILhhbIjP0OVllCwXH7vLOSvkgHXiZsgsDWDiV0tOA//FimntkJ2eA2gVsHEqQ5qDJwHSf3WBdsKBRwCGzqBEEII4RvH8kvgS6HpfMjVzcP4dHRddVpn+z8+oyN1ICSEEKIzmn5/U81AKRo4W6FDfceCLoTaIhRw6FDfkRIBQggheoGSgTIE9/OBSMvJgEjAIbifj1b3SQghhFQUJQNlcLOXYFFf7bYMXty3MU1fTAghRG9QMqCBoFbumNmtoVb29Xk3Lwxu5a6VfRFCCCHaQKMJNDQlsAEcLcVYsP82lGpWrgmMhAIOIgGHxX0bUyJACCFE79CVgXIIauWO4zMC4F/XAQDKLCzMX+5f1wHHZwRQIkAIIUQv0ZWBcnKzl2D7GD88jE/Hzigpwh8kQCqTF5rUiENeQ6HAhk4Y3sadRg0QQgjRa9RnQAsyFUpEyzKRo1TDVCSAp4MFdRYkhBDCO02/v+kbSwssxCI0drEpe0VCCCFED1HNACGEEGLkKBkghBBCjBwlA4QQQoiRo2SAEEIIMXKUDBBCCCFGjpIBQgghxMhRMkAIIYQYOUoGCCGEECNHyQAhhBBi5CgZIIQQQowcJQOEEEKIkaNkgBBCCDFylAwQQgghRo6SAUIIIcTIUTJACCGEGDlKBgghhBAjJ9JkJcYYACAtLU2nwRBCCCFEe/K/t/O/x0uiUTKQnp4OAHBzc6tkWIQQQgipaunp6bCxsSlxOcfKShcAqNVqxMXFwcrKChzHaTVAQgghhOgGYwzp6elwcXGBQFByZYBGyQAhhBBCqi8qICSEEEKMHCUDhBBCiJGjZIAQQggxcpQMEEIIIUaOkgFCCCHEyFEyQAghhBg5SgYIIYQQI/d/chSV0qCwvZoAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load first element of dataset to graph.\n",
    "graph = convert_to_graph(dataset[0])\n",
    "\n",
    "# Vizualizing the graph (molecule).\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.set_title('Graph representation of the molecule structure')\n",
    "nx.draw_networkx(graph)\n",
    "plt.savefig(\"molecul.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b964c63d-14c6-44fe-819d-5de6f8205448",
   "metadata": {},
   "source": [
    "Only feature we are missing for every graph is adjacency matrix. We can directly obtain it using the function adjacency_matrix from networkx library. In order for it to become a tensor, we will make custom function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1069,
   "id": "9d78ba49-2e94-4ab9-b3b6-d9c9593fbb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for obtaining and converting adjacency matrix to tensor\n",
    "def adj_matrix_totensor(graph):\n",
    "    \"\"\" \n",
    "    Function for obtaining and converting adjacency matrix to tensor.\n",
    "    \n",
    "    Args:\n",
    "        graph (nx.Graph): graph for which we want get adjacency matrix\n",
    "        \n",
    "    Returns:\n",
    "        torch.sparse_coo_tensor: adjacency_matrix\n",
    "    \"\"\" \n",
    "    \n",
    "    adj = nx.adjacency_matrix(graph)\n",
    "    adj = sp.coo_array(adj)\n",
    "    \n",
    "    return torch.sparse_coo_tensor(\n",
    "        torch.LongTensor(np.vstack((adj.row, adj.col))),\n",
    "        torch.FloatTensor(adj.data),\n",
    "        torch.Size(adj.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c515878-3e52-499a-bc9c-65dacaf71e91",
   "metadata": {},
   "source": [
    "## 2. Implementing different Graph Convolution and Pooling layers\n",
    "### 2.1. Normal Convolution (Graph Convolution)  \n",
    "The normal convolution layer aggregates neighbor data without any specific attention mechanism. The equation for normal convolution layer in matrix form can be written as:  \n",
    "$$\n",
    "H^{(l+1)} = \\sigma\\left( \\tilde{A}H^{(l)}W_l^\\top + H^{(l)}B_l^\\top \\right)\n",
    "$$  where $\\tilde{A}$ is a diagonal matrix containing inverse of the degree and $\\mathbf{W}$ and $\\mathbf{B}$ are trainable weight matrices of the layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1070,
   "id": "ec27e160-1896-4253-812f-760087c2a075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we implement basic Graph Convolution Layer\n",
    "class GraphConv(nn.Module):\n",
    "    \"\"\" Normal Convolution layer implementing simple neighbor aggregation. \"\"\"\n",
    "    \n",
    "    def __init__(self, in_features, out_features, activation=None):\n",
    "        \"\"\"\n",
    "        Initialize the graph convolution layer.\n",
    "        \n",
    "        Args:\n",
    "            in_features (int): number of input node features.\n",
    "            out_features (int): number of output node features.\n",
    "            activation (nn.Module or callable): activation function to apply. (optional)\n",
    "        \"\"\"\n",
    "        \n",
    "        super().__init__()\n",
    "        self.activation = activation\n",
    "        \n",
    "        # Learnable weight matrices using linear layers\n",
    "        self.weight = nn.Linear(in_features, out_features, bias=False)\n",
    "        nn.init.xavier_uniform_(self.weight.weight)\n",
    "        \n",
    "        self.bias = nn.Linear(in_features, out_features, bias=False)\n",
    "    \n",
    "    def forward(self, x, adj):\n",
    "        \"\"\"\n",
    "        Aggregate the neighbours' node embeddings.\n",
    "        \n",
    "        Args:\n",
    "            x (list of tesor): list of mini batch input node embeddings of shape of each (num_nodes, in_features)\n",
    "            adj (list of tensor): list of mini batch sparse adjacency matrix of the graph of shape of each (num_nodes, num_nodes)\n",
    "        \n",
    "        Returns:\n",
    "            list of tensors: list of mini batch output node embeddings after aggregation, shape of each (num_nodes, out_features)\n",
    "        \"\"\"\n",
    "        \n",
    "        # First we form A_tilde matrix, assuming that there is no nodes without neighbors within a graph\n",
    "        adj = adj / adj.sum(1, keepdims=True).clamp(min=1)\n",
    "        \n",
    "        # Then we aggregate all the neighbours\n",
    "        x_agg = torch.matmul(adj, x)\n",
    "        \n",
    "        # Now we perform matrix multiplication with learnable weight matrices\n",
    "        x = self.weight(x_agg) + self.bias(x)\n",
    "        \n",
    "        # Applying selected activation function\n",
    "        if self.activation is not None:\n",
    "            x = self.activation(x)\n",
    "            \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca1de48-2422-49ba-b849-270ffb6258d1",
   "metadata": {},
   "source": [
    "### 2.2. GraphSAGE (Customized Aggregation)  \n",
    "The equation for the GraphSAGE layer is:\n",
    "$$\n",
    "\\mathbf{h}_v^{(l+1)} = \\sigma\\left( \\mathbf{W}_l \\cdot \\mathrm{CONCAT} \\left[\\mathbf{h}_v^{(l)}, \\mathrm{AGG} \\left(\\left\\{\\mathbf{h}_u^{(l)}, \\forall u\\in N(v) \\right\\}\\right) \\right] \\right),\n",
    "$$\n",
    "where $v$ index the node, $l$ the layer, $\\mathbf{h}$ are the node embeddings, $\\sigma$ is a non-linearity, $N(v)$ is the set of neighbor of node $v$, and $\\mathbf{W}$ is the trainable weight matrix of the layer. $\\mathrm{CONCAT}$ is the concatenation operation, while $\\mathrm{AGG}$ is an arbitrary aggregation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1071,
   "id": "692737e6-a099-4541-8bb0-891ac49cbde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphSAGEConv(nn.Module):\n",
    "    \"\"\" GraphSAGE convolutional layer. \"\"\"\n",
    "    \n",
    "    def __init__(self, in_features, out_features, aggregation, activation=None):\n",
    "        \"\"\"\n",
    "        Initialize the GraphSAGE convolutional layer.\n",
    "        \n",
    "        Args:\n",
    "            in_features (int): number of input node features\n",
    "            out_features (int): number of output node features\n",
    "            aggregation (MeanAggregation or se other aggregation classes below): aggregation function to apply, as x_agg = aggegration(x, adj).\n",
    "            activation (nn.Module or callable): activation function to apply. (optional)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.aggregation = aggregation\n",
    "        self.activation = activation\n",
    "        \n",
    "        # One learnable weight matrix using the linear layer\n",
    "        self.weight = nn.Linear(in_features * 2, out_features, bias=False)\n",
    "        nn.init.xavier_uniform_(self.weight.weight)\n",
    "        \n",
    "    def forward(self, x, adj):\n",
    "        \"\"\"\n",
    "        Perform graph convolution operation.\n",
    "        \n",
    "        Args:\n",
    "            x (Tensor): Input node features of shape (num_nodes, in_features).\n",
    "            adj (Tensor): Adjacency matrix of the graph, typically sparse, shape (num_nodes, num_nodes).\n",
    "        \n",
    "        Returns:\n",
    "            Tensor: Output node features after graph convolution, shape (num_nodes, out_features).\n",
    "        \"\"\"\n",
    "        # First we aggregate neighbours'node embeddings, shape stays the same (num_nodes, in_features)\n",
    "        x_agg = self.aggregation(x, adj)\n",
    "        \n",
    "        # Concatanate node features with its neighbouring ones, shape is now (num_nodes, 2*in_features)\n",
    "        concatenation = torch.cat([x, x_agg], dim=-1)\n",
    "        \n",
    "        # Apply linear layer, shape is (num_nodes, out_features)\n",
    "        x = self.weight(concatenation)\n",
    "        \n",
    "        # apply activation function\n",
    "        if self.activation is not None:\n",
    "            x = self.activation(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d2c609-c8fb-4229-8868-72c1da14c4c8",
   "metadata": {},
   "source": [
    "#### 2.2.1. Aggregation functions for GraphSAGE layer  \n",
    "We need to provide different options for GraphSAGE aggregation functions, so they will be implementented on the side. Implemented aggregation functions will be: Mean (as in Normal Convolution layer), Max Pool and SqrtDegAggregation. SqrtDegAggregation is defined by the formula:\n",
    "$$\\mathrm{AGG} \\left(\\left\\{\\mathbf{h}_u^{(l)}, \\forall u\\in N(v) \\right\\}\\right) = \\sum_{u\\in N(v)} \\frac{\\mathbf{h}_u^{(l)}}{\\sqrt{\\mathrm{deg}(v)}\\sqrt{\\mathrm{deg}(u)}},$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1072,
   "id": "c7f47824-1d38-464a-b0b2-06383af33c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanAggregation(nn.Module):\n",
    "    \"\"\" Aggregate node features by averaging over the neighbourhood. \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, x, adj):\n",
    "        \n",
    "        adj = adj / adj.sum(1, keepdims=True)\n",
    "        x_agg = torch.matmul(adj, x)\n",
    "        \n",
    "        return x_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1073,
   "id": "7abd5bba-c8cf-43d0-b143-1d7e0e7bba7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPoolAggregation(nn.Module):\n",
    "    \"\"\" Aggregate node features by taking the maxiumum over the transformed neighbourhood. \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, x, adj):\n",
    "        num_samples = x.size(dim=0)\n",
    "        in_features = x.size(dim=1)\n",
    "        x_agg = torch.zeros(num_samples, in_features)\n",
    "        \n",
    "        for i in range(num_samples):\n",
    "            # For every node we find indexes od its neighbours\n",
    "            neighbours_index = torch.nonzero(adj[i]).squeeze(-1)\n",
    "            neighbours = torch.index_select(x, 0, neighbours_index)\n",
    "            \n",
    "            # We max pool features of all neighbours\n",
    "            x_agg[i], indices = torch.max(neighbours, dim=0)\n",
    "            \n",
    "        return x_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1074,
   "id": "712445e8-2820-435b-8023-542a6eefd40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SqrtDegAggregation(nn.Module):\n",
    "    \"\"\" Aggregate node features by summing over the neighborhood and normalizing by the degrees. \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, x, adj):\n",
    "        # First, same part as in the MeanAggregation\n",
    "        adj = adj / torch.sqrt(adj.sum(1, keepdims=True))\n",
    "        \n",
    "        #Multiply every node embedding with its deg{-1}\n",
    "        x = x / torch.sqrt(adj.sum(1, keepdims=True))\n",
    "        x_agg = torch.matmul(adj, x)\n",
    "        \n",
    "        return x_agg "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbfd3f8-d3f2-461d-8fac-e9d0c38862b1",
   "metadata": {},
   "source": [
    "### 2.3. Attention-based Convolution  \n",
    "Attention-based Convolution applies attention mechanism to neighbor aggregation. The equation for Attention-based Convolution at layer *l* can be defined as follows: \n",
    "$$\\mathbf{h}_v^{'(l)}=\\mathbf{W}_l\\mathbf{h}_v^{(l)}$$  \n",
    "$$\\mathbf{h}_v^{(l+1)}=\\sigma\\left(\\sum_{u \\in N(v) \\cup \\{v\\}}a_{vu}^{(l)} \\cdot \\mathbf{h}_{u}^{'(l)}\\right)$$  \n",
    "where $a_{vu}^{(l)}$ is normalized attention weights between node node $v$ and its neighbour node $u$ as well as itself. Below you can find formula to compute attention weights. $N(v) \\cup \\{v\\}$ is the union of the neighbours of node $v$ and itself.  \n",
    "The attention score $e_{vu}$ between node $v$ and its neighbour $v$ is calculated as the dot product between a learnable weight vector and concatenation of their features and passed through a LeakyReLU activation:\n",
    "$$e_{vu}=LeakyRELU\\left(\\mathbf{S}^T \\cdot CONCAT \\left(\\mathbf{h}_{v}^{'(l)}, \\mathbf{h}_{u}^{'(l)}\\right)\\right),$$\n",
    "where $\\mathbf{S}$ is a learnable weight vector, shared amongst all nodes. Note that this attention score is applied to the transformed node embeddings.  \n",
    "After calculating the attention scores, we apply the softmax function to obtain normalized attention weights. These weights represent the importance of each neighbour node in relation to node $v$:\n",
    "$$a_{vu}=\\frac{exp\\left(e_{vu}\\right)}{\\sum_{k \\in N(v) \\cup \\{v\\}}exp\\left(e_{vk}\\right)}.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1075,
   "id": "0559c5cb-b9f6-4450-929e-85399ba84bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionConv(nn.Module):\n",
    "    \"\"\" Attention-based convolution layer. \"\"\"\n",
    "    \n",
    "    def __init__(self, in_features, out_features, activation=None):\n",
    "        \"\"\" Initialize Attention-based convolution layer.\n",
    "        \n",
    "            Args: \n",
    "                in_features (int) : number of node's input features\n",
    "                out_features (int): number of nodes' output features\n",
    "                activation (nn.Module or callable): activation function to be applied at the end\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # Initialize two linear layers for learnable weights\n",
    "        self.weight = nn.Linear(in_features, out_features, bias=False) # All nodes transformation\n",
    "        nn.init.xavier_uniform_(self.weight.weight)\n",
    "        \n",
    "        self.attention_score = nn.Linear(2 * out_features, 1, bias=False) # Weights for calculating attention score\n",
    "        nn.init.xavier_uniform_(self.attention_score.weight)\n",
    "        \n",
    "        # Initialize activation function\n",
    "        self.activation = activation\n",
    "        \n",
    "    def forward(self, x, adj):\n",
    "        \"\"\" Aggregate node emeddings using attention-based mechanism. \n",
    "            \n",
    "            Args:\n",
    "                x (tensor): contains all node's embeddings, shape (num_nodes, in_features)\n",
    "                adj (tensor): adjacency matrix of the graph, shape (num_nodes, num_nodes)\n",
    "            \n",
    "            Returns:\n",
    "                (tensor): node's features after attention-based aggregation, shape (num_nodes, out_features)\n",
    "            \n",
    "        \"\"\"\n",
    "        num_nodes = x.size(dim=0)\n",
    "        \n",
    "        # First, apply linear transformation to every node's embedding\n",
    "        x = self.weight(x) # new shape is (num_nodes, out_features)\n",
    "        \n",
    "        # Because in every calculation root node is included, we will add I matrix to adj\n",
    "        adj = adj + torch.eye(num_nodes)\n",
    "        \n",
    "        x_agg = []\n",
    "        # Updating each node embedding\n",
    "        for i in range(num_nodes):\n",
    "            \n",
    "            # Get features of root (current) node\n",
    "            root = x[i]\n",
    "\n",
    "            # For one node, extract all of its'neighbours index\n",
    "            neighbours_index = torch.nonzero(adj[i]).squeeze(-1)\n",
    "            neighbours = torch.index_select(x, 0, neighbours_index)\n",
    "            \n",
    "            # Concatenate root node features with its neighbours\n",
    "            concatenated = torch.cat((root.repeat(neighbours.size(dim=0), 1), neighbours), 1) # shape is (num_neighbours_ith_node+1, 2*out_features)\n",
    "            \n",
    "            # Another linear transformation, followed by LeakyReLU\n",
    "            e = F.leaky_relu(self.attention_score(concatenated)) # shape is (num_neighbours_ith_node+1, 1)\n",
    "            \n",
    "            # Calculate normalized attention weights\n",
    "            a = F.softmax(e, 0)\n",
    "            \n",
    "            # Attention-based step\n",
    "            output = torch.mm(torch.transpose(concatenated, 0, 1), neighbours)\n",
    "            output = torch.sum(output, 0).unsqueeze(0)\n",
    "            x_agg.append(output)\n",
    "       \n",
    "        x = torch.cat(x_agg, dim=0)\n",
    "        \n",
    "        if self.activation is not None:\n",
    "            x = self.activation(x)\n",
    "            \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff1da9d-5c99-4a78-b077-daf2aecb5310",
   "metadata": {},
   "source": [
    "### 2.4. Mean Pooling  \n",
    "\n",
    "Given a graph with node features $\\mathbf{X} \\in \\mathbb{R}^{N \\times D}$, where $N$ is the number of nodes and $D$ is a feature dimension, mean pooling computes the graph level representation $\\mathbf{h}_{global}$, as the mean (average) of all node features: \n",
    "$$\\mathbf{h}_{global}=\\frac{1}{N} \\sum_{i=1}^{N}\\mathbf{X}_i.$$\n",
    "Here, $\\mathbf{X}_i$ represents the feature vector of $i$th node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1076,
   "id": "2eed4cc3-2f75-4e26-a34b-0e44d8904c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanPooling(nn.Module):\n",
    "    \"\"\" Does Mean Pooling on all node features. \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\" Initialize MeanPooling layer. \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\" \n",
    "        Computes Mean Pooling on all node features.\n",
    "            \n",
    "        Args:\n",
    "            x (tensor): all node features of shape (num_nodes, num_features)\n",
    "                \n",
    "        Returns:\n",
    "            h_global (tensor): node features after mean pool, shape (num_features, )       \n",
    "        \"\"\"\n",
    "        h_global = torch.mean(x, 0)\n",
    "        \n",
    "        return h_global"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebb49ef-1b12-4ef1-a6d4-72cefd110fee",
   "metadata": {},
   "source": [
    "### 2.5. Max Pooling  \n",
    "\n",
    "Max pooling selects maximume value for each feature dimension across all nodes to create the graph-level representation:  \n",
    "$$\\mathbf{h}_{global}\\left[d\\right] = \\max_{i=1}^{N}\\mathbf{X}_{i}\\left[d\\right]$$ \n",
    "for each feature dimension $d$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1077,
   "id": "c6a3d664-61f7-43a7-9f24-d4c7c34b64f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPooling(nn.Module):\n",
    "    \"\"\" Selects maximume value for each feature dimension across all nodes. \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\" Initialize Max Pooling layer. \"\"\"\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\" \n",
    "        Computes Max Pooling on all node features.\n",
    "            \n",
    "        Args:\n",
    "            x (tensor): all node features of shape (num_nodes, num_features)\n",
    "                \n",
    "        Returns:\n",
    "            h_global (tensor): node features after max pool, shape (num_features, )       \n",
    "        \"\"\"\n",
    "        h_global, indices = torch.max(x, 0, keepdims=True)\n",
    "        \n",
    "        return h_global"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c184ac0-ab04-4794-b73a-9f6211b750d5",
   "metadata": {},
   "source": [
    "## 3. Custom Network Design with Node Features  \n",
    "### 3.1. Custom Network Arhitecture  \n",
    "\n",
    "In this section, we will design different neural network arhitectures using layers that we implemented in the previous section, with user-defined choices on number and types of layers. For simplicity, the network's prediction head will have only one pooling layer (Mean or Max) and one Fully Connected layer.   \n",
    "\n",
    "**Note 1.:** As we get one value for the final output of the network, we will have to apply sigmoid function on it in order to decide to which class we will associate the graph. However, we will not include the sigmoid activation to the prediction head so that we can used *torch.nn.BCEWithLogitsLoss*, which is more numerically stable than *torch.nn.BCELoss*.  \n",
    "**Note 2.:** Even though it is recommended to use *nn.BatchNorm1d()* in GNN arhitecutres, here it yielded very unsatissfying results, so it was not included."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ab8815-b8aa-43bc-9fc2-b2228aa7ed61",
   "metadata": {},
   "source": [
    "#### 3.1.1. Graph Convolution Neural Network  \n",
    "\n",
    "Now that we've had implemented helpers function we can create first model for graph classification - using only Normal Convoluton layers. We can set arbirary number of layers, activation or pooling functions, as well as dropout probability. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1078,
   "id": "7bcb5ab8-034c-4ed6-9b1f-07026fa3663b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNConv(nn.Module):\n",
    "    \"\"\" A full graph neural network for graph classification using only Graph Convolution layers. \"\"\"\n",
    "    \n",
    "    def __init__(self, num_features, conv_dims, activation, pooling, dropout=0.):\n",
    "        \"\"\" \n",
    "        Initialize GNN model for graph classification.\n",
    "        \n",
    "        Args:\n",
    "            num_features (int): number of input node features\n",
    "            conv_dims (list of int): number of hidden features in each graph convolution layers\n",
    "            activation (nn.Module or callable): activation function to apply\n",
    "            pooling (MeanPooling or MaxPooling object): pooling type for prediction head\n",
    "            dropout (float): dropout probability (optional)\n",
    "        \"\"\" \n",
    "        super().__init__()\n",
    "        self.activation = activation\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # We stack layers\n",
    "        self.conv_layers = nn.ModuleList()\n",
    "        self.conv_layers.append(GraphConv(num_features, conv_dims[0], activation)) # First layer separate, because we give num_nodes as parameter\n",
    "        \n",
    "        for i in range(len(conv_dims)-2):\n",
    "            self.conv_layers.append(GraphConv(conv_dims[i], conv_dims[i+1], activation))\n",
    "        \n",
    "        self.conv_layers.append(GraphConv(conv_dims[-2], conv_dims[-1], None))\n",
    "            \n",
    "        # Prediction head: one pooling layer + fully connected layer (to give one predicted output)\n",
    "        self.pooling = pooling\n",
    "        self.fully_connected = nn.Linear(conv_dims[-1], 1)\n",
    "        \n",
    "    def forward(self, x, adj):\n",
    "        \"\"\" \n",
    "        Perform forward pass for graph classification.\n",
    "        \n",
    "        Args:\n",
    "            x (tensor): input node features of shape (num_nodes, num_features)\n",
    "            adj (tensor): adjacency matrix of the graph, shape (num_nodes, num_nodes)\n",
    "            \n",
    "        Returns: \n",
    "            float: probability to which of two classes the graph belongs\n",
    "        \"\"\" \n",
    "        # Apply multiple graph convolution layers\n",
    "        for layer in self.conv_layers:\n",
    "            x = layer(x, adj)\n",
    "            x = self.dropout(x)\n",
    "            \n",
    "        # Predict probability to which of two classes the graph belongs\n",
    "        x = self.pooling(x)\n",
    "        x = self.fully_connected(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07503acd-b51c-4395-aac0-23697c8c11ee",
   "metadata": {},
   "source": [
    "Next arhitecture, we're going to implement is the one using only GraphSAGE layers. It differs from the previous one because it uses arbitrary aggregation function (from the implemented options) and does concatenation with the root node. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1079,
   "id": "5b607e4d-e1cf-44dc-a6a9-e7fe96898318",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNGraphSAGE(nn.Module):\n",
    "    \"\"\" A full graph neural network for graph classification using only GraphSAGE layers. \"\"\"\n",
    "    \n",
    "    def __init__(self, num_features, conv_dims, activation, pooling, aggregation, dropout=0.):\n",
    "        \"\"\" \n",
    "        Initialize GNN model for graph classification.\n",
    "        \n",
    "        Args:\n",
    "            num_features (int): number of input node features\n",
    "            conv_dims (list of int): number of hidden features in each graph convolution layers\n",
    "            activation (nn.Module or callable): activation function to apply\n",
    "            pooling (MeanPooling or MaxPooling object): pooling type for prediction head\n",
    "            aggregation (MeanAggregation or ... other aggregation type object (see possible options in section 2.2.1)): aggregation for GraphSAGE layer\n",
    "            dropout (float): dropout probability (optional)\n",
    "        \"\"\" \n",
    "        super().__init__()\n",
    "        self.activation = activation\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # We stack layers\n",
    "        self.conv_layers = nn.ModuleList()\n",
    "        self.conv_layers.append(GraphSAGEConv(num_features, conv_dims[0], aggregation, activation)) # First layer separate, because we give num_nodes as parameter\n",
    "        \n",
    "        for i in range(len(conv_dims)-2):\n",
    "            self.conv_layers.append(GraphSAGEConv(conv_dims[i], conv_dims[i+1], aggregation, activation))\n",
    "        \n",
    "        self.conv_layers.append(GraphSAGEConv(conv_dims[-2], conv_dims[-1], aggregation, None))\n",
    "            \n",
    "        # Prediction head: one pooling layer + fully connected layer (to give one predicted output)\n",
    "        self.pooling = pooling\n",
    "        self.fully_connected = nn.Linear(conv_dims[-1], 1)\n",
    "        \n",
    "    def forward(self, x, adj):\n",
    "        \"\"\" \n",
    "        Perform forward pass for graph classification.\n",
    "        \n",
    "        Args:\n",
    "            x (tensor): input node features of shape (num_nodes, num_features)\n",
    "            adj (tensor): adjacency matrix of the graph, shape (num_nodes, num_nodes)\n",
    "            \n",
    "        Returns: \n",
    "            float: probability to which of two classes the graph belongs\n",
    "        \"\"\" \n",
    "        # Apply multiple graph convolution layers\n",
    "        for layer in self.conv_layers:\n",
    "            x = layer(x, adj)\n",
    "            x = self.dropout(x)\n",
    "            \n",
    "        # Predict probability to which of two classes the graph belongs\n",
    "        x = self.pooling(x)\n",
    "        x = self.fully_connected(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20a891a-de3a-4f62-99a4-b971c9e2629a",
   "metadata": {},
   "source": [
    "#### 3.1.3. Graph Attention Network Arhitecture   \n",
    "Next arhitecture we are going to implement is the one using attention layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1080,
   "id": "86eec421-b354-4ef8-aea7-e6728ea8079a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNAttention(nn.Module):\n",
    "    \"\"\" A full graph neural network for graph classification using only Attention layers. \"\"\"\n",
    "    \n",
    "    def __init__(self, num_features, conv_dims, activation, pooling, dropout=0.):\n",
    "        \"\"\" \n",
    "        Initialize GNN model for graph classification.\n",
    "        \n",
    "        Args:\n",
    "            num_features (int): number of input node features\n",
    "            conv_dims (list of int): number of hidden features in each graph convolution layers\n",
    "            activation (nn.Module or callable): activation function to apply\n",
    "            pooling (MeanPooling or MaxPooling object): pooling type for prediction head\n",
    "            dropout (callable): dropout function (optional)\n",
    "        \"\"\" \n",
    "        super().__init__()\n",
    "        self.activation = activation\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # We stack layers\n",
    "        self.conv_layers = nn.ModuleList()\n",
    "        self.conv_layers.append(AttentionConv(num_features, conv_dims[0], activation)) # First layer separate, because we give num_nodes as parameter\n",
    "        \n",
    "        for i in range(len(conv_dims)-2):\n",
    "            self.conv_layers.append(AttentionConv(conv_dims[i], conv_dims[i+1], activation))\n",
    "        \n",
    "        self.conv_layers.append(AttentionConv(conv_dims[-2], conv_dims[-1], activation))\n",
    "            \n",
    "        # Prediction head: one pooling layer + fully connected layer (to give one predicted output)\n",
    "        self.pooling = pooling\n",
    "        self.fully_connected = nn.Linear(conv_dims[-1], 1)\n",
    "        \n",
    "    def forward(self, x, adj):\n",
    "        \"\"\" \n",
    "        Perform forward pass for graph classification.\n",
    "        \n",
    "        Args:\n",
    "            x (list of tensors): list of mini batch input node features, each of shape (num_nodes, num_features)\n",
    "            adj (list of tensors): list of mini batch adjacency matrix of the graph, each of shape (num_nodes, num_nodes)\n",
    "            \n",
    "        Returns: \n",
    "            tensor: probability to which of two classes the graphs of the mini batch belong, shape (minibatch_size,)\n",
    "        \"\"\" \n",
    "        # Apply multiple graph convolution layers\n",
    "        for layer in self.conv_layers:\n",
    "            x = layer.forward(x, adj)\n",
    "            x = self.dropout(x)\n",
    "        \n",
    "        # Predict probability to which of two classes the graph belongs\n",
    "        x = self.pooling(x)\n",
    "        x = self.fully_connected(x)\n",
    "        \n",
    "        return x "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578d82e3-4378-45b2-a277-0c058c4dff21",
   "metadata": {},
   "source": [
    "### 3.2. Data Partitioning \n",
    "\n",
    "We are going to split the dataset into training $\\left(70 \\% \\right)$, validation $\\left(15 \\% \\right)$ and test sets $\\left(15 \\% \\right)$ for consistent evaluation. Also, we are going to make small function that will serve as iterator for our training procedure.    \n",
    "\n",
    "But before we do that, we have to tackle the problem of imbalanced dataset. After trying, several different approached (undersampling, weight_decay > 0, dropout), the one that gave best results is actually **stratified train, test, splitting**. This method splits data in such way, so that it keeps the ratio of the two classes the same in every of these subsets. For this purpose, we are going to use *DataLoader* from *torch.utils.data* and *train_test_split* function from *sklearn.model_selection*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1081,
   "id": "78e0af9d-3931-49c3-a51a-a6f2d97afe9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will split data into traning, testing and validation subsets\n",
    "def train_test_val_split(dataset):\n",
    "    \"\"\" \n",
    "    Splits dataset into training, test and validation subset.\n",
    "    \n",
    "    Args:\n",
    "        dataset (dataset) : dataset containing all the graphs\n",
    "        \n",
    "    Return:\n",
    "        X_training, y_training, X_validating, y_validating, X_testing, y_testing (lists): subsets of labels and data for train, test and validation\n",
    "    \"\"\" \n",
    "    \n",
    "    # Extract node features, edge features, edge index and labels\n",
    "    edge_feat = dataset['edge_attr'] \n",
    "    node_feat = dataset['node_feat']\n",
    "    edge_index = dataset['edge_index']\n",
    "    labels = dataset['y']\n",
    "\n",
    "    # In order to have both node features and edge features stored together, we're going to merge them\n",
    "    merged_data = [] \n",
    "    for i in range(len(node_feat)):\n",
    "        graphs = [node_feat[i], edge_index[i], edge_feat[i]]\n",
    "        merged_data.append(graphs)\n",
    "\n",
    "    # We use train_test_split to keep the ratio of both classes the same in both train and test\n",
    "    X_training, X_test, y_training, y_test = train_test_split(merged_data, labels, train_size=0.7, random_state=42, shuffle=True, stratify=labels)\n",
    "    X_testing, X_validating, y_testing, y_validating = train_test_split(X_test, y_test, train_size=0.5, random_state=42, shuffle=True, stratify=y_test)\n",
    "\n",
    "    return X_training, y_training, X_validating, y_validating, X_testing, y_testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b316af-e520-4b4d-9772-7afee36a157e",
   "metadata": {},
   "source": [
    "As it will be more easier to iterate, we will convert the lists back to the dictionaries. The upcoming function, serves this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1082,
   "id": "e3c91bbb-beab-45c3-9fac-8c3211e02d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(x, y):\n",
    "    \"\"\" \n",
    "    Reverts lists of node features, edge index, edge features and labels back to dictionary.\n",
    "    \n",
    "    Args:\n",
    "        x (list) : node features, edge index, edge features of each subset\n",
    "        y (list) : labels of each subset\n",
    "        \n",
    "    Returns:\n",
    "        data (list of dictionaries): contains all graphs from the subset as form of list of dictionaries\n",
    "        \n",
    "    \"\"\"\n",
    "    data = []\n",
    "    for i in range(len(x)):\n",
    "        \n",
    "        single_graph = {'node_feat' : x[i][0], 'edge_index': x[i][1], 'edge_feat': x[i][2], 'y': y[i]}\n",
    "        data.append(single_graph)\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1083,
   "id": "ab5bc59c-89c2-46a6-b40d-8d769c860866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we split the data\n",
    "X_training, y_training, X_validating, y_validating, X_testing, y_testing = train_test_val_split(dataset)\n",
    "\n",
    "# And revert it back to dictionaries\n",
    "train_data = make_dataset(X_training, y_training)\n",
    "validation_data = make_dataset(X_validating, y_validating)\n",
    "test_data = make_dataset(X_testing, y_testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909798c1-9b06-4466-b30f-08d0a11357de",
   "metadata": {},
   "source": [
    "So we have split the data into training, testing and validation sets. We will now make DataLoader, so we can iterate more easily through the sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1084,
   "id": "0bff608b-30ce-41ab-913c-6cf62d3c53f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphDataset(Dataset):\n",
    "    \"\"\" Makes object for torch.utils.data DataLoader. \"\"\"\n",
    "    def __init__(self, data):\n",
    "        \"\"\" \n",
    "        Initialized GraphDataset object.\n",
    "        \n",
    "        Args:\n",
    "            data (list of dict): dictionary containing all parameters from the graph\n",
    "        \n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\" Get number of graphs in the dataset. \"\"\"\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\" \n",
    "        Get graph on the index position from dataset.\n",
    "        \n",
    "        Args:\n",
    "            index (int): index position\n",
    "        \"\"\"\n",
    "        return self.data[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1085,
   "id": "08755757-9464-4130-aaa6-de7b00ca47f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can initialize 3 DataLoaders - for training, validation and test sets\n",
    "data_train = GraphDataset(train_data)\n",
    "train_loader = DataLoader(data_train, batch_size=1, shuffle=True)\n",
    "\n",
    "data_validation = GraphDataset(validation_data)\n",
    "validation_loader = DataLoader(data_validation, batch_size=1, shuffle=True)\n",
    "\n",
    "data_test = GraphDataset(test_data)\n",
    "test_loader = DataLoader(data_test, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a550085c-2205-4ea0-81b8-c2997e51c246",
   "metadata": {},
   "source": [
    "### 3.4. Training and Validation Utilities\n",
    "\n",
    "When we have build all of our models, it's time to train, validate and test our solutions. First function we are going to implement is the one that does **single** train step on the data corresponding to that set, meaning it will go through all of the graphs in the train data set and update trainable parameters according to the selected loss function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1086,
   "id": "55fe9d2d-43d3-4280-8850-d0b1638d5041",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(train_loader, model, optimizer, loss_fn, adj_matrix_type, atten_layer_type):\n",
    "    \"\"\"\n",
    "    One training step over whole training dataset.\n",
    "    \n",
    "    Args:\n",
    "        train_loader (DataLoader) : training data\n",
    "        model (nn.Module): model we are looking to train\n",
    "        optimizer (torch.optim): optimizer for training\n",
    "        loss_fn (nn.Loss): selected loss function (it will be nn.BCEWithLogitsLoss())\n",
    "        adj_matrix_type (\"normal\" or \"weighted\"): adjacency matrix for GCN normal or weighted selector\n",
    "        atten_layer_type (\"normal\" or \"edge\"): type of the GAT layer model trains (necessary because we need to have edge features as well)\n",
    "        \n",
    "    Return:\n",
    "        float : average loss over one training step\n",
    "    \"\"\"\n",
    "    # Set model for training\n",
    "    model.train()\n",
    "    \n",
    "    # This variable will accumulate loss over the whole training dataset\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    for batch in train_loader:\n",
    "        \n",
    "        # Get node features of current graph\n",
    "        x = batch['node_feat'].squeeze(0)\n",
    "        \n",
    "        # Get edge features of current graph\n",
    "        e = batch['edge_feat'].squeeze(0)\n",
    "        \n",
    "        # Make its adjacency matrix \n",
    "        if adj_matrix_type == \"normal\":\n",
    "            adj = adj_matrix_totensor(convert_to_graph(batch)).to_dense()\n",
    "        else:\n",
    "            adj = weighted_adjacency_matrix(batch)\n",
    "        \n",
    "        # Take ground truth label for this graph\n",
    "        labels = batch['y']\n",
    "        \n",
    "        # Get model output\n",
    "        if atten_layer_type == \"normal\":\n",
    "            out = model(x, adj)\n",
    "            \n",
    "        else:\n",
    "            out = model(x, e, adj)\n",
    "        out = out.view(-1, 1)\n",
    "        \n",
    "        # Calculate the loss for current prediction\n",
    "        loss = loss_fn(out, labels.view(-1, 1).float())\n",
    "        \n",
    "        # Set Set the gradient of trainable parameters to 0\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Automatically calculate the gradient of trainable parameters\n",
    "        loss.backward()\n",
    "        \n",
    "        # Automatically update the trainable parameters using the gradient\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "    # Average loss\n",
    "    average_loss = train_loss / len(train_loader)\n",
    "        \n",
    "    return average_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e38b35-b9f5-4fca-a4dc-617c25da0022",
   "metadata": {},
   "source": [
    "We will also need some metrics beside loss, to measure how our model performs on training, validation and test data. We are going to calculate **accuracy** (percentage of samples that exactly belong to a predicted class).    \n",
    "\n",
    "In many casses this would have been enough to measure model performance, but as we established earlier, our dataset is imbalanced (there is twice as much samples from the class labeled as 1 than from the class labeled with 0), which can lead to our model being more biased toward one (majority) class. Taking this into account, accuracy can lead us to the false assumption regarding quallity of our model, since it can be high even in the case when model is only predicting one class. Therefore, we have to consider employing other metrics such as **F1 score**. F1 score is very useful metric, especially in the case of unevenly distributed classes. It is calculated using the following formula:  \n",
    "\n",
    "$$ F1 score = \\frac{2 \\cdot Precision \\cdot Recall}{Precision + Recall},$$\n",
    "\n",
    "where *Precision* denotes the number of true positive predictions (correctly predicted postive instances) divided by the total number of positive predictions (true positives and false positives). Precision measures positive class accuracy. It is given with the formula:\n",
    "\n",
    "$$ Precision = \\frac{TP}{TP+FP}$$\n",
    "\n",
    "On the other hand, *Recall*, also known as sensitivity, is the number of true positive predictions divided by the total number of actual positive instances (true positives and false negatives). Recall measures model's ability to idenitfy all the relevant instances. Recall can be calculated using the formula:\n",
    "\n",
    "$$ Recall = \\frac{TP}{TP + FN}$$\n",
    "\n",
    "That being said, F1 score ranges from 0 to 1, with 1 being the best possible value. A higher F1 score suggests better balance between precision and recall. Usually, F1 score equal or larger to 0.7 is considered good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1087,
   "id": "4b53a6d9-c4f8-4f58-a5e7-dd26125592fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad() # because it's only evaluation we don't need it to do the training\n",
    "def acc_f1_metrics(train_loader, model, adj_matrix_type, atten_layer_type):\n",
    "    \"\"\" \n",
    "    Calculate accuracy and F1 score for the training data.\n",
    "    \n",
    "    Args:\n",
    "        train_loader (DataLoader) : data loader of the train dataset\n",
    "        model (nn.Module): trained model\n",
    "        adj_matrix_type (\"normal\" or \"weighted\"): adjacency matrix for GCN normal or weighted selector\n",
    "        atten_layer_type (\"normal\" or \"edge\"): type of the GAT layer model trains (necessary because we need to have edge features as well)\n",
    "        \n",
    "    Returns:\n",
    "        train_acc (float): accuracy on the train set\n",
    "        train_f1 (float): accuracy on the train set\n",
    "    \"\"\"\n",
    "\n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Lists that will gather ground truths and predictions\n",
    "    ground_truth = []\n",
    "    classification = []\n",
    "    \n",
    "    for batch in train_loader:\n",
    "        \n",
    "        # Get node features of current graph\n",
    "        x = batch['node_feat'].squeeze(0)\n",
    "        \n",
    "        # Get edge features of current graph\n",
    "        e = batch['edge_feat'].squeeze(0)\n",
    "        \n",
    "        # Make its adjacency matrix \n",
    "        if adj_matrix_type == \"normal\":\n",
    "            adj = adj_matrix_totensor(convert_to_graph(batch)).to_dense()\n",
    "        else:\n",
    "            adj = weighted_adjacency_matrix(batch)\n",
    "        \n",
    "        # Take ground truth label for this graph\n",
    "        labels = batch['y']\n",
    "        \n",
    "        # Get model output\n",
    "        if atten_layer_type == \"normal\":\n",
    "            out = model(x, adj)\n",
    "            \n",
    "        else:\n",
    "            out = model(x, e, adj)\n",
    "        out = out.view(-1, 1)\n",
    "        \n",
    "        # Make prediction\n",
    "        class_pred = torch.sigmoid(out)\n",
    "        predictions = (class_pred > 0.5).float()\n",
    "        ground_truth.extend(labels.numpy().tolist())\n",
    "        classification.extend(predictions.numpy().tolist())\n",
    "    \n",
    "    # Get train accuracy and F1 score using functions from sklearn\n",
    "    train_acc = accuracy_score(ground_truth, classification)\n",
    "    train_f1 = f1_score(ground_truth, classification)\n",
    "    \n",
    "    return train_acc, train_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1088,
   "id": "d67a81ce-545d-4698-b319-8c707c8a30a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One similar function to the previous one, just for validation set (different because it includes calculating the loss)\n",
    "@torch.no_grad() # we have evaluation mode, so it will be computationally inefficent to do gradients again\n",
    "def val_acc_f1_metrics(validation_loader, model, loss_fn, adj_matrix_type, atten_layer_type):\n",
    "    \"\"\" \n",
    "    Calculate accuracy and F1 score on the validation data.\n",
    "    \n",
    "    Args:\n",
    "        validation_loader (DataLoader): data loader for validation data\n",
    "        model (nn.Module): trained model\n",
    "        loss_fn (nn.Module or callable): loss function used for the training of the model\n",
    "        adj_matrix_type (\"normal\" or \"weighted\"): adjacency matrix for GCN normal or weighted selector\n",
    "        atten_layer_type (\"normal\" or \"edge\"): type of the GAT layer model trains (necessary because we need to have edge features as well)\n",
    "    \n",
    "    Returns:\n",
    "        averga_loss (float): loss on the validation data\n",
    "        validation_acc (float): accuracy on the validation data\n",
    "        validation_f1 (float): f1 score on the validation data\n",
    "        right_class (list): list of properly classified graphs\n",
    "        wrong_class (list): list of wrongly classified graphs\n",
    "        \n",
    "    \"\"\" \n",
    "    \n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Define loss \n",
    "    validation_loss = 0.0\n",
    "    \n",
    "    # Lists that will gather ground truths and predictions\n",
    "    ground_truth = []\n",
    "    classification = []\n",
    "    right_class = []\n",
    "    wrong_class = []\n",
    "    \n",
    "    for batch in validation_loader:\n",
    "        \n",
    "        # Get node features of current graph\n",
    "        x = batch['node_feat'].squeeze(0)\n",
    "        \n",
    "        # Get the edge features of current graph\n",
    "        e = batch['edge_feat'].squeeze(0)\n",
    "        \n",
    "        # Make its adjacency matrix \n",
    "        if adj_matrix_type == \"normal\":\n",
    "            adj = adj_matrix_totensor(convert_to_graph(batch)).to_dense()\n",
    "        else:\n",
    "            adj = weighted_adjacency_matrix(batch)\n",
    "        \n",
    "        # Take ground truth label for this graph\n",
    "        labels = batch['y']\n",
    "        \n",
    "        # Get model output\n",
    "        if atten_layer_type == \"normal\":\n",
    "            out = model(x, adj)\n",
    "            \n",
    "        else:\n",
    "            out = model(x, e, adj)\n",
    "        out = out.view(-1, 1)\n",
    "        \n",
    "        # Calculate the loss\n",
    "        loss = loss_fn(out, labels.view(-1, 1).float())\n",
    "        validation_loss += loss.item()\n",
    "        \n",
    "        # Make prediction\n",
    "        class_pred = torch.sigmoid(out)\n",
    "        predictions = (class_pred > 0.5).float()\n",
    "        ground_truth.extend(labels.numpy().tolist())\n",
    "        classification.extend(predictions.numpy().tolist())\n",
    "        \n",
    "        if predictions.numpy() == labels.numpy():\n",
    "            right_class.append(batch)\n",
    "        else:\n",
    "            wrong_class.append(batch)\n",
    "        \n",
    "    # Average loss\n",
    "    average_loss = validation_loss / len(validation_loader)\n",
    "    \n",
    "    # Get train accuracy and F1 score using functions from sklearn\n",
    "    validation_acc = accuracy_score(ground_truth, classification)\n",
    "    validation_f1 = f1_score(ground_truth, classification)\n",
    "    \n",
    "    return average_loss, validation_acc, validation_f1, right_class, wrong_class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b828560c-9b9e-4777-86d8-a5d9a95cb6d8",
   "metadata": {},
   "source": [
    "### 3.5. Incorporating Edge features \n",
    "\n",
    "Part of our data set are **edge features** and we can possible incorporate those into our layers and see if we get any improvement. Edge features are organized as 4-dimensional hot encoding vectors, one per edge. We will try two different approaches to incorporate edge features in our existing layers and they will be presented in the following sections."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295457cf-da81-444e-963f-eda4b45f1116",
   "metadata": {},
   "source": [
    "#### 3.5.1. Incorporating Edge features to GCN layer  \n",
    "\n",
    "When it comes to GCN layers, the most common approach to include edge features is to give weights to edges, meaning that in adjacency matrix, we can place weights on existant edges rather than 1. As we mentioned before, we initially have 4-dimensional hot encoding vector for a edge features. Consequently, we can put 4 different weights on the edges, so we can distinguish between each one of them in the adjacency matrix. If we output edge features of a signle graph, we can conclude that most of the edges are encoded with [1, 0, 0, 0], which probably reprsents most common type of the bond in the molecule. In our weighted ajdacency matrix, we will put larger weight on the edges that are not the most common ones. Possible weights will be 0.25, 0.5, 0.75 and 1.    \n",
    "\n",
    "Now, we need to create custom function that will implement such adjacency matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1089,
   "id": "fbbbfbe1-fb28-4f8b-a6de-b87ac5a26ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_adjacency_matrix(graph):\n",
    "    \"\"\"\n",
    "    Creates weighted adjacency matrix according to the edge features from a single graph.\n",
    "    Coding is in such way: \n",
    "    [1, 0, 0, 0] -> 0.25\n",
    "    [0, 1, 0, 0] -> 0.5\n",
    "    [0, 0, 1, 0] -> 0.75 \n",
    "    [0, 0, 0, 1] -> 1\n",
    "    \n",
    "    Args:\n",
    "        graph (dict) : one graph from data loader\n",
    "    \n",
    "    Returns:\n",
    "        weighted_adj (tensor) : weighted adjacency matrix according to the coding    \n",
    "    \"\"\"\n",
    "    # Extract all the necessary information (number of nodes, edge features, edge_list)\n",
    "    num_nodes = graph[\"node_feat\"].squeeze(0).size(dim=0)\n",
    "    edge_features = graph[\"edge_feat\"].squeeze(0)\n",
    "    edge_list = graph[\"edge_index\"].squeeze()\n",
    "\n",
    "    \n",
    "    # Create new tensor which will serve us as new adjacency matrix\n",
    "    weighted_adj = torch.zeros(num_nodes, num_nodes, dtype=torch.float32)\n",
    "    \n",
    "    # Make a tensor of all weights\n",
    "    weights = torch.argmax(edge_features, dim=1, keepdims=True) + 1\n",
    "    weights = weights / 4\n",
    "    \n",
    "    # Iterate over all weights and edge list to create weighted matrix\n",
    "    for idx, weight in enumerate(weights):\n",
    "        weighted_adj[edge_list[0][idx], edge_list[1][idx]] = weight\n",
    "        \n",
    "    return weighted_adj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc109cb-09ec-4b26-a940-2751f8bb0774",
   "metadata": {},
   "source": [
    "#### 3.5.2. Incorporating Edge features to GAT layer  \n",
    "\n",
    "GraphSAGE layer is not very convenient for incorporating edge features, so we are going to try to include them into GAT layer. There is lack of scienctific papers that acknowledges edge features in such manner in GAT layers, but similar approach is used in the PyG implementation of GAT.  \n",
    "First, we are going to apply linear transformation to features and than concatenate corresponding edge features to pairs of node features:    \n",
    "\n",
    "$$\\mathbf{edge}_{uv}^{(l+1)}=\\mathbf{W}_{edge}\\mathbf{edge}_{uv}^{(l)}$$    \n",
    "\n",
    "$$e_{vu}=LeakyRELU\\left(\\mathbf{S}^T \\cdot CONCAT \\left(\\mathbf{h}_{v}^{'(l)}, \\mathbf{h}_{u}^{'(l)}, \\mathbf{edge}_{vu}^{(l+1)}\\right)\\right)$$\n",
    "\n",
    "As it can be inferred, we are going to pass both node and edge features from layer to layer.  \n",
    "Let's try to make this layer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1090,
   "id": "e0388f64-4507-4743-8e04-67e19b756ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionEdgeConv(nn.Module):\n",
    "    \"\"\" Attention-based convolution which incorporates edge features. \"\"\" \n",
    "    \n",
    "    def __init__(self, in_features_nodes, out_features_nodes, in_features_edges, out_features_edges, activation=None):\n",
    "        \"\"\" \n",
    "        Initialize Attention-based convolution layer that incorporates edge features.\n",
    "        \n",
    "        Args:\n",
    "            in_features_nodes (int) : number of node's input features\n",
    "            out_features_nodes (int) : number of node's output features\n",
    "            \n",
    "            in_features_edges (int) : number of edge's input features\n",
    "            out_features_edges (int) : number of edge's output features\n",
    "            \n",
    "            activation (nn. Module or callable) : activation function to be applied\n",
    "            \n",
    "        \"\"\" \n",
    "        super().__init__()\n",
    "        self.out_features_edge = out_features_edges\n",
    "        \n",
    "        # Initialize three linear layers for learnable weights\n",
    "        self.weight_nodes = nn.Linear(in_features_nodes, out_features_nodes, bias=False) # All nodes transformation\n",
    "        nn.init.xavier_uniform_(self.weight_nodes.weight)\n",
    "        \n",
    "        self.weight_edges = nn.Linear(in_features_edges, out_features_edges, bias=False)\n",
    "        nn.init.xavier_uniform_(self.weight_edges.weight)\n",
    "        \n",
    "        self.attention_score = nn.Linear(2 * out_features_nodes + out_features_edges, 1, bias=False)\n",
    "        nn.init.xavier_uniform_(self.attention_score.weight)\n",
    "        \n",
    "        # Initialize activation function\n",
    "        self.activation = activation\n",
    "        \n",
    "    def forward(self, x, e, adj):\n",
    "        \"\"\"\n",
    "        Aggregate node embeddings using attention-based mechanism that incorporates edge features.\n",
    "        \n",
    "        Args:\n",
    "            x (tensor) : contains all node's embeddings, shape (num_nodes, in_features_nodes)\n",
    "            e (tensor) : contains all edge's embeddings, shape (num_edges, in_feature_edges)\n",
    "            adj (tensor) : adjacency matrix of the graph, shape (num_nodes, num_nodes)\n",
    "            \n",
    "        Returns:\n",
    "            tensor : node's features after attention based aggregation, shape (num_nodes, out_features)\n",
    "        \"\"\" \n",
    "        num_nodes = x.size(dim=0)\n",
    "        num_edges = e.size(dim=0)\n",
    "        \n",
    "        # First, we apply linear transformation to both nodes and edges\n",
    "        x = self.weight_nodes(x) # new shape is (num_features, out_features_nodes)\n",
    "        e = self.weight_edges(e) # new shape is (num_edges, out_features_edges)\n",
    "        \n",
    "        # Because in every calculation root node is included, we will add I matrix to adj\n",
    "        adj = adj + torch.eye(num_nodes)\n",
    "        \n",
    "        x_agg = []\n",
    "        j = 0 # This will help us iterate over edge list\n",
    "        # Updating each node embedding using node embeddings of its neighbours and their edge features\n",
    "        for i in range(num_nodes):\n",
    "            \n",
    "            # Get features of root (current) node\n",
    "            root = x[i]\n",
    "            \n",
    "            # For the root-root node connection we will padd zeros\n",
    "            padd = torch.zeros(1, self.out_features_edge)\n",
    "            \n",
    "            # Get indexes of all neighbours and number of them\n",
    "            neighbours_index = torch.nonzero(adj[i]).squeeze(-1)\n",
    "            num_neighbours = neighbours_index.size(dim=0) - 1\n",
    "            \n",
    "            # Extract all neighbours embeddings\n",
    "            neighbours = torch.index_select(x, 0, neighbours_index)\n",
    "            \n",
    "            # Extract all edge features that belong to this neighbours\n",
    "            features = e[j:j+num_neighbours]\n",
    "            merg_features = torch.cat((padd, features), 0)\n",
    "            \n",
    "            # Concatenate node features and edge features\n",
    "            concatenated = torch.cat((root.repeat(neighbours.size(dim=0), 1), neighbours, merg_features), 1) # shape is (num_neighbours_ith_node+1, 2*out_features_nodes+out_features_edges)\n",
    "            \n",
    "            # Another linear transformation\n",
    "            lin_trans = F.leaky_relu(self.attention_score(concatenated)) # shape is (num_neighbours_ith_node+1, 1)\n",
    "            \n",
    "            # Calculate normalized attention weights\n",
    "            a = F.softmax(lin_trans, 0)\n",
    "            \n",
    "            # Attention-based step\n",
    "            output = torch.mm(torch.transpose(concatenated, 0, 1), neighbours)\n",
    "            output = torch.sum(output, 0).unsqueeze(0)\n",
    "            x_agg.append(output)\n",
    "       \n",
    "        x = torch.cat(x_agg, dim=0)\n",
    "        \n",
    "        if self.activation is not None:\n",
    "            x = self.activation(x)\n",
    "            \n",
    "        return x, e    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7772a1a0-35be-4f31-9ec5-bd160ce98b0b",
   "metadata": {},
   "source": [
    "We will now make network arhitecture from the attention-based layers that include edge embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1091,
   "id": "a5b98bfb-6ebf-49b7-9344-6c3174a32342",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNAttentionEdge(nn.Module):\n",
    "    \"\"\" A full graph neural network for graph classification using only Attention layers. \"\"\"\n",
    "    \n",
    "    def __init__(self, num_node_features, num_edge_features, conv_dims, edge_dims, activation, pooling, dropout=0.):\n",
    "        \"\"\" \n",
    "        Initialize GNN model for graph classification.\n",
    "        \n",
    "        Args:\n",
    "            num_node_features (int): number of input node features\n",
    "            num_edge_features (int): number of input edge features\n",
    "            conv_dims (list of int): number of hidden features in each graph convolution layers for nodes\n",
    "            edge_dims (list of int): number of hidden features in each graph convolution layers for edges (#NOTE: conv_dims and edge_dims must be same size)\n",
    "            activation (nn.Module or callable): activation function to apply\n",
    "            pooling (MeanPooling or MaxPooling object): pooling type for prediction head\n",
    "            dropout (callable): dropout function (optional)\n",
    "        \"\"\" \n",
    "        super().__init__()\n",
    "        self.activation = activation\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # We stack layers\n",
    "        self.conv_layers = nn.ModuleList()\n",
    "        self.conv_layers.append(AttentionEdgeConv(num_node_features, conv_dims[0], num_edge_features, edge_dims[0], activation)) # First layer separate, because we give num_nodes as parameter\n",
    "        \n",
    "        for i in range(len(conv_dims)-2):\n",
    "            self.conv_layers.append(AttentionEdgeConv(conv_dims[i], conv_dims[i+1], edge_dims[i], edge_dims[i+1], activation))\n",
    "        \n",
    "        self.conv_layers.append(AttentionEdgeConv(conv_dims[-2], conv_dims[-1], edge_dims[-2], edge_dims[-1], activation))\n",
    "            \n",
    "        # Prediction head: one pooling layer + fully connected layer (to give one predicted output)\n",
    "        self.pooling = pooling\n",
    "        self.fully_connected = nn.Linear(conv_dims[-1], 1)\n",
    "        \n",
    "    def forward(self, x, e, adj):\n",
    "        \"\"\" \n",
    "        Perform forward pass for graph classification.\n",
    "        \n",
    "        Args:\n",
    "            x (list of tensors): list of mini batch input node features, each of shape (num_nodes, num_features)\n",
    "            adj (list of tensors): list of mini batch adjacency matrix of the graph, each of shape (num_nodes, num_nodes)\n",
    "            \n",
    "        Returns: \n",
    "            tensor: probability to which of two classes the graphs of the mini batch belong, shape (minibatch_size,)\n",
    "        \"\"\" \n",
    "        # Apply multiple graph convolution layers\n",
    "        for layer in self.conv_layers:\n",
    "            x, e = layer.forward(x, e, adj)\n",
    "            x = self.dropout(x)\n",
    "        \n",
    "        # Predict probability to which of two classes the graph belongs\n",
    "        x = self.pooling(x)\n",
    "        x = self.fully_connected(x)\n",
    "        \n",
    "        return x "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60612b2-6c48-45dd-b1ba-804362453a03",
   "metadata": {},
   "source": [
    "### 3.6. Complete training and testing\n",
    "\n",
    "We will now combine everything to train and evaluate our model. For the start, we are going to the defined everything necessary for the training: hyperparameters (number of epochs, learning rate, number of layers, type of activation and pooling functions), model, loss function and optimizer and implement hyperparameter tuning for some of the parameters, particularly **number of convolution layers**, **learning rate**, **type of pooling layer** and **type of aggregation layer** for GraphSAGE network arhitecture.  \n",
    "**NOTE:** This kind of grid search is very computationaly costly if we increase the number of possible options for the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1092,
   "id": "9392ae02-e620-4dee-8934-24d9ceb64615",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 7 # number of input node features\n",
    "conv_dims = [[16, 16], [32, 16], [8, 8, 8], [16, 16, 16]] # possible options for number of hidden features for each graph convolution layer\n",
    "edge_dims = [[4, 4], [8, 8], [16, 16]] # possible options for number of hidden features for attention layer that includes edge features\n",
    "activation = nn.LeakyReLU() # we are going to choose same activation function\n",
    "dropout = [0., 0.001] # possible values for dropout probability\n",
    "loss_fn = nn.BCEWithLogitsLoss() # loss function\n",
    "learning_rate = [0.01, 0.001, 0.0001]\n",
    "num_epochs = [50, 100]\n",
    "pooling = [MaxPooling(), MeanPooling()]\n",
    "aggregation = [MeanAggregation(), MaxPoolAggregation(), SqrtDegAggregation()]\n",
    "adj_matrix_type = \"normal\" # \"normal\" - no weigthed adj matrix/\"weighted\" - weighted adj matrix\n",
    "atten_layer_type = \"edges\" # \"normal\" - without edge features/\"edges\" - with edge features\n",
    "layer_type = \"GATE\" # possible options \"GCN\", \"GraphSAGE\", \"GAT\", \"GATE\"(Attention Edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1093,
   "id": "8f91b202-959f-4825-a8f2-b80ccaf9a33a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define function that trains a model for certain number of epochs\n",
    "def train_epochs(train_loader, validation_loader, model, epochs, optimizer, loss_fn, adj_matrix_type, atten_layer_type):\n",
    "    \"\"\" \n",
    "    Train in the model for specified number of epochs. \n",
    "    \n",
    "    Args:\n",
    "        train_loader (DataLoader): loader for train data\n",
    "        validation_loader (DataLoader): loader for validation data\n",
    "        model (nn.Module): model that has to be trained\n",
    "        epochs (int): number of epochs to train model\n",
    "        optimizer (torch.optim): optimizer \n",
    "        loss_fn: (nn.Module or callable): nn.BCEWithLossLogits()\n",
    "        adj_matrix_type: \"normal\"\n",
    "        atten_layer_type: \"normal\"\n",
    "        \n",
    "    Returns:\n",
    "        train_accuracy (list): accuracy over all training epochs\n",
    "        train_loss (list): loss over all training epochs\n",
    "        train_f1_score (list): F1 score over all training epochs\n",
    "        \n",
    "        validation_accuracy (list): validation accuracy over all epochs\n",
    "        validation_loss (list): validation loss over all epochs\n",
    "        validation_f1_score(list): validation F1 score over all epochs\n",
    "    \"\"\"    \n",
    "    \n",
    "    # Define lists to store accuracy, loss and f1 score for train dataset\n",
    "    train_accuracy = []\n",
    "    train_loss = []\n",
    "    train_f1_score = []\n",
    "    \n",
    "    # Define lists to store accuracy, loss and f1 score for validation dataset\n",
    "    validation_accuracy = []\n",
    "    validation_loss = []\n",
    "    validation_f1_score = []\n",
    "    \n",
    "    # We are going to run a loop for certain number of epochs to train the model\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        # Run one train step\n",
    "        train_av_loss = train_step(train_loader, model, optimizer, loss_fn, adj_matrix_type, atten_layer_type)\n",
    "        train_loss.append(train_av_loss)\n",
    "        \n",
    "        \n",
    "        # Calculate accuracy and F1 score on the train data\n",
    "        train_acc, train_f1 = acc_f1_metrics(train_loader, model, adj_matrix_type, atten_layer_type)\n",
    "        train_accuracy.append(train_acc)\n",
    "        train_f1_score.append(train_f1)\n",
    "        \n",
    "        # Calculate all the metrics on the validation data\n",
    "        validation_av_loss, validation_acc, validation_f1, _, _ = val_acc_f1_metrics(validation_loader, model, loss_fn, adj_matrix_type, atten_layer_type)\n",
    "        validation_accuracy.append(validation_acc)\n",
    "        validation_loss.append(validation_av_loss)\n",
    "        validation_f1_score.append(validation_f1)\n",
    "    \n",
    "    return train_accuracy, train_loss, train_f1_score, validation_accuracy, validation_loss, validation_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1094,
   "id": "09d47cff-671a-444a-b68c-846aa2216e47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function for hyperparameter tuning for GCN, GAT, GraphSAGE and GATEdge\n",
    "def hyperparameter_tuning_gcn_gat(train_loader, validation_loader, test_loader, num_features, conv_dims, edge_dims, activation, dropout, loss_fn, learning_rate, num_epochs, pooling, adj_matrix_type, atten_layer_type, layer_type):\n",
    "    \"\"\"\n",
    "    Function for hyperparameter tuning. Does Grid Search over all possible values of hyperparameters to find\n",
    "    the ones that give the best results. \n",
    "    \n",
    "    Args:\n",
    "        train_loader (DataLoader): train dataset\n",
    "        validation_loader (DataLoader): validation dataset\n",
    "        test_loader (DataLoader): test dataset\n",
    "        num_features (int) : number of input node features\n",
    "        conv_dims (list of lists of int): contains all the size of hidden layers we are going to check\n",
    "        activation (nn.Module or callable): activation function (always LeakyReLU)\n",
    "        dropout (list of float): possible dropout probabilities\n",
    "        loss_fn (nn.Module or callable ): loss function (always BCEWithLogitsLoss)\n",
    "        learning_rate (list of float): possible learning rates\n",
    "        num_epochs (list of int): possible number of epochs\n",
    "        pooling (list of nn.Module or callable): possible options for pooling layer\n",
    "        aggregation (list of nn.Module or callable): possible options for aggregation function for GraphSAGE\n",
    "        adj_matrix_type: \"normal\"\n",
    "        atten_layer_type: \"normal\"\n",
    "        layer_type: \"GCN\", \"GraphSAGE\", \"GAT\"\n",
    "        \n",
    "    Returns:\n",
    "        best_params: list with best params, resulting with best accuracy on test set\n",
    "        best_metr_val: list that contains best loss, accuracy and F1 score on validaton set\n",
    "        best_metr_test: list that contains best loss, accuracy and F1 score on test set\n",
    "        best_train_accuracy: train accuracy through epochs on the model that got best test accuracy\n",
    "        best_train_loss: train loss through epochs on the model that got the best test accuracy\n",
    "        best_train_f1: train f1 score through epochs on the model that got the best test accuracy\n",
    "        best_val_acc: validation accuracy through epochs on the model that got the best test accuracy\n",
    "        best_val_loss: validation loss through epochs on the model that got the best test accuracy\n",
    "        best_val_f1: validation f1 score through epochs on the model that got the best test accuracy\n",
    "    \"\"\"\n",
    "\n",
    "    best_accuracy = -1.\n",
    "    best_metr_val = []\n",
    "    best_metr_test = []\n",
    "    best_params = []\n",
    "    \n",
    "    best_train_acc = []\n",
    "    best_train_loss = []\n",
    "    best_train_f1 = []\n",
    "    best_val_acc = []\n",
    "    best_val_loss = []\n",
    "    best_val_f1 = []\n",
    "    \n",
    "    for layer in conv_dims:\n",
    "        for drop in dropout:\n",
    "            for lr in learning_rate:\n",
    "                for ne in num_epochs:\n",
    "                    for pool in pooling:\n",
    "                        for edge in edge_dims: #--> NOTE: Uncomment this for GraphSAGE hyperparameter tuning or replace with (for edge in edge_dims:) for GATEdge.\n",
    "                            \n",
    "                            if layer_type == \"GCN\":\n",
    "                                model = GNNConv(num_features=num_features, conv_dims=layer, activation=activation, dropout=drop, pooling=pool)\n",
    "                            \n",
    "                            if layer_type == \"GAT\":\n",
    "                                model = GNNAttention(num_features=num_features, conv_dims=layer, activation=activation, dropout=drop, pooling=pool)\n",
    "                                \n",
    "                            if layer_type == \"GATE\": # --> NOTE: Uncomment this for GATEdge hyperparameter tuning\n",
    "                                model = model = GNNAttentionEdge(num_node_features=num_features, num_edge_features=4, conv_dims=layer, edge_dims=edge, activation=activation, dropout=drop, pooling=pool)\n",
    "                                \n",
    "                            #if layer_type == \"GraphSAGE\": #--> NOTE: Uncomment this for GraphSAGE hypereparameter tuning\n",
    "                                #model = GNNGraphSAGE(num_features=num_features, conv_dims=layer, activation=activation, dropout=drop, pooling=pool, aggregation=agg)\n",
    "                            \n",
    "                            optimizer = torch.optim.Adam(model.parameters(), lr=lr) \n",
    "                            train_accuracy, train_loss, train_f1_score, validation_accuracy, validation_loss, validation_f1_score = train_epochs(train_loader, validation_loader, model, ne, optimizer, loss_fn, adj_matrix_type, atten_layer_type)\n",
    "                            val_loss, val_accuracy, val_f1_score, _, _ = val_acc_f1_metrics(validation_loader, model, loss_fn, adj_matrix_type, atten_layer_type)\n",
    "                            \n",
    "                            if val_accuracy > best_accuracy:\n",
    "                                best_params = []\n",
    "                                best_metr_val = []\n",
    "                                best_metr_test = []\n",
    "                                \n",
    "                                # Capture best parameter and metrics up till now on validation and test set\n",
    "                                best_params = [layer, drop, lr, ne, pool]\n",
    "                                best_metr_val = [val_loss, val_accuracy, val_f1_score]\n",
    "                                \n",
    "                                test_loss, test_accuracy, test_f1, _, _ = val_acc_f1_metrics(test_loader, model, loss_fn, adj_matrix_type, atten_layer_type)\n",
    "                                best_metr_test = [test_loss, test_accuracy, test_f1]\n",
    "                                \n",
    "                                # Capture results on training and validation sets\n",
    "                                best_train_acc = train_accuracy\n",
    "                                best_train_loss = train_loss\n",
    "                                best_train_f1 = train_f1_score\n",
    "                                best_val_acc = validation_accuracy\n",
    "                                best_val_loss = validation_loss\n",
    "                                best_val_f1 = validation_f1_score\n",
    "                                \n",
    "    return best_params, best_metr_val, best_metr_test, best_train_acc, best_train_loss, best_train_f1, best_val_acc, best_val_loss, best_val_f1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a1ad2b-7ba2-479a-83fd-19db4e19fe77",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params, best_metr_val, best_metr_test, best_train_acc, best_train_loss, best_train_f1, best_val_acc, best_val_loss, best_val_f1 = hyperparameter_tuning_gcn_gat(train_loader, validation_loader, test_loader, num_features, conv_dims, edge_dims, activation, dropout, loss_fn, learning_rate, num_epochs, pooling, adj_matrix_type, atten_layer_type, layer_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a75615-c776-489a-b171-816cf09a38c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the best parameters obtained\n",
    "print(\"Best result was obtained for the following parameters on the:\", layer_type, end=\"\\n\")\n",
    "print(\"Number and size of layers:\", best_params[0], end=\"\\n\")\n",
    "print(\"Dropout probability:\", best_params[1], end=\"\\n\")\n",
    "print(\"Learning rate:\", best_params[2], end=\"\\n\")\n",
    "print(\"Number of training epochs:\", best_params[3], end=\"\\n\")\n",
    "print(\"Type of pooling:\", best_params[4], end=\"\\n\")\n",
    "\n",
    "# Plotting the change of accuracy, loss and F1 score over the epochs on training and validation data, that give the best test accuracy\n",
    "# First, we have to make x-axis\n",
    "x_axis = np.arange(best_params[3]) # best_params[3] is number of epochs\n",
    "\n",
    "# First we plot accuracy\n",
    "plt.figure(figsize=[4.8, 4.8])\n",
    "plt.plot(x_axis, np.array(best_train_acc), '-*', color='maroon')\n",
    "plt.plot(x_axis, np.array(best_val_acc), '-*', color='blue')\n",
    "plt.title(\"Accuracy comparison on Train and Validation data\")\n",
    "plt.grid(visible=True)\n",
    "plt.xlabel(\"Epochs [n]\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend([\"train_acc\", \"validation_acc\"])\n",
    "plt.savefig(\"acc_sage.png\")\n",
    "plt.show()\n",
    "\n",
    "# Plot loss\n",
    "plt.figure(figsize=[4.8, 4.8])\n",
    "plt.plot(x_axis, np.array(best_train_loss), '-*', color='maroon')\n",
    "plt.plot(x_axis, np.array(best_val_loss), '-*', color='blue')\n",
    "plt.title(\"Loss comparison on Train and Validation data\")\n",
    "plt.grid(visible=True)\n",
    "plt.xlabel(\"Epoch [n]\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend([\"train_loss\", \"validation_loss\"])\n",
    "plt.savefig(\"loss_sage.png\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Plot F1 score\n",
    "plt.figure(figsize=[4.8, 4.8])\n",
    "plt.plot(x_axis, np.array(best_train_f1), '-*', color='maroon')\n",
    "plt.plot(x_axis, np.array(best_val_f1), '-*', color='blue')\n",
    "plt.title(\"F1 Score comparison on Train and Validation data\")\n",
    "plt.grid(visible=True)\n",
    "plt.xlabel(\"Epochs [n]\")\n",
    "plt.ylabel(\"F1 Score\")\n",
    "plt.legend([\"train_F1\", \"validation_F1\"])\n",
    "plt.savefig(\"f1_sage.png\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Printing accuracy, loss and F1 score for the validation set\n",
    "print(\"Validation accuracy:\", best_metr_val[1], end=\"\\n\")\n",
    "print(\"Validation loss:\", best_metr_val[0], end=\"\\n\")\n",
    "print(\"Validation F1 score:\", best_metr_val[2], end=\"\\n\")\n",
    "\n",
    "# Printing accuracy, loss and F1 score for the test set\n",
    "print(\"Test accuracy:\", best_metr_test[1], end=\"\\n\")\n",
    "print(\"Test loss:\", best_metr_test[0], end=\"\\n\")\n",
    "print(\"Test F1 score:\", best_metr_test[2], end=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2666503a-df24-4bca-a0d7-c20065040ec3",
   "metadata": {},
   "source": [
    "Now, we are going to test the performance of the layer with edge features included. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e38085-c779-459a-b4c0-8cf4c12622b7",
   "metadata": {},
   "source": [
    "### 3.7 Self-check functions   \n",
    "These functions served in my implementation procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b744f8-cad4-476e-b81b-29190715a1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 7  # number of input node features\n",
    "num_edge_features = 4  # number of edge features\n",
    "conv_dims = [16, 16]  # list of hidden features in each graph convolution layer\n",
    "edge_dims = [8, 8]\n",
    "activation = nn.LeakyReLU()  # activation function \n",
    "dropout = 0.  # dropout probability\n",
    "loss_fn = nn.BCEWithLogitsLoss() # loss function\n",
    "learning_rate = 0.001 # learning rate\n",
    "num_epochs = 100 # the number of training epochs\n",
    "pooling = MaxPooling()\n",
    "aggregation = MeanAggregation()\n",
    "adj_matrix_type = \"normal\"\n",
    "atten_layer_type = \"edges\"\n",
    "\n",
    "# initializing the GNN model\n",
    "#model = GNNGraphSAGE(num_features=num_features, conv_dims=conv_dims, activation=activation, dropout=dropout, pooling=pooling, aggregation=aggregation)\n",
    "#model = GNNConv(num_features=num_features, conv_dims=conv_dims, activation=activation, dropout=dropout, pooling=pooling)\n",
    "#model = GNNAttention(num_features=num_features, conv_dims=conv_dims, activation=activation, dropout=dropout, pooling=pooling)\n",
    "model = GNNAttentionEdge(num_node_features=num_features, num_edge_features=num_edge_features, conv_dims=conv_dims, edge_dims=edge_dims, activation=activation, dropout=dropout, pooling=pooling)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e33b61-d226-4b9f-bf11-2e818e48d01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are going to define lists that will store all the values for accuracy, loss and F1 for training and validation\n",
    "\n",
    "train_accuracy = []\n",
    "train_loss = []\n",
    "train_f1_score = []\n",
    "\n",
    "validation_accuracy = []\n",
    "validation_loss = []\n",
    "validation_f1_score = []\n",
    "\n",
    "# We are going to run a loop for a number of epochs to calculate all of these metrics\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    print(f\"Epoch: {epoch:d}\", end=\"\\n\")\n",
    "    \n",
    "    # Run one train step\n",
    "    train_av_loss = train_step(train_loader, model, optimizer, loss_fn, adj_matrix_type, atten_layer_type)\n",
    "    train_loss.append(train_av_loss)\n",
    "    \n",
    "    # Print loss\n",
    "    print(f\"Train loss: {train_av_loss:.5f}\", end=\"\\n\")\n",
    "    \n",
    "    # Calculate accuracy and F1 score on the train data\n",
    "    train_acc, train_f1 = acc_f1_metrics(train_loader, model, adj_matrix_type, atten_layer_type)\n",
    "    train_accuracy.append(train_acc)\n",
    "    train_f1_score.append(train_f1)\n",
    "    \n",
    "    # Print metrics\n",
    "    print(f\"Train accuracy: {train_acc:.5f}\", end=\"\\n\")\n",
    "    print(f\"Train F1 score: {train_f1:.5f}\", end=\"\\n\")\n",
    "    \n",
    "    # Calculate all the metrics on the validation data\n",
    "    validation_av_loss, validation_acc, validation_f1, _, _ = val_acc_f1_metrics(validation_loader, model, loss_fn, adj_matrix_type, atten_layer_type)\n",
    "    validation_accuracy.append(validation_acc)\n",
    "    validation_loss.append(validation_av_loss)\n",
    "    validation_f1_score.append(validation_f1)\n",
    "    \n",
    "    # Print loss and metrics\n",
    "    print(f\"Validation loss: {validation_av_loss:.5f}\", end=\"\\n\")\n",
    "    print(f\"Validation accuracy: {validation_acc:.5f}\", end=\"\\n\")\n",
    "    print(f\"Validation F1 score: {validation_f1:.5f}\", end=\"\\n\")\n",
    "    print(end=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256de089-0101-4299-8d36-1b7658d0d10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting collected figures\n",
    "\n",
    "# First, we have to make x-axis\n",
    "x_axis = np.arange(num_epochs)\n",
    "\n",
    "# First we plot accuracy\n",
    "plt.figure(figsize=[4.8, 4.8])\n",
    "plt.plot(x_axis, np.array(train_accuracy), '-*', color='maroon')\n",
    "plt.plot(x_axis, np.array(validation_accuracy), '-*', color='blue')\n",
    "plt.title(\"Accuracy comparison on Train and Validation data\")\n",
    "plt.grid(visible=True)\n",
    "plt.xlabel(\"Epochs [n]\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend([\"train_acc\", \"validation_acc\"])\n",
    "plt.show()\n",
    "\n",
    "# Plot loss\n",
    "plt.figure(figsize=[4.8, 4.8])\n",
    "plt.plot(x_axis, np.array(train_loss), '-*', color='maroon')\n",
    "plt.plot(x_axis, np.array(validation_loss), '-*', color='blue')\n",
    "plt.title(\"Loss comparison on Train and Validation data\")\n",
    "plt.grid(visible=True)\n",
    "plt.xlabel(\"Epoch [n]\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend([\"train_loss\", \"validation_loss\"])\n",
    "plt.show()\n",
    "\n",
    "# Plot F1 score\n",
    "plt.figure(figsize=[4.8, 4.8])\n",
    "plt.plot(x_axis, np.array(train_f1_score), '-*', color='maroon')\n",
    "plt.plot(x_axis, np.array(validation_f1_score), '-*', color='blue')\n",
    "plt.title(\"F1 Score comparison on Train and Validation data\")\n",
    "plt.grid(visible=True)\n",
    "plt.xlabel(\"Epochs [n]\")\n",
    "plt.ylabel(\"F1 Score\")\n",
    "plt.legend([\"train_F1\", \"validation_F1\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33fa70a-4204-4fbd-8ea7-0155434e7b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And finally results on the train\n",
    "test_loss, test_accuracy, test_f1_score, right_class, wrong_class = val_acc_f1_metrics(test_loader, model, loss_fn, adj_matrix_type, atten_layer_type)\n",
    "\n",
    "print(f\"Test accuracy: {test_accuracy:.5f}\", end=\"\\n\")\n",
    "print(f\"Test loss: {test_loss:.5f}\", end=\"\\n\")\n",
    "print(f\"Test F1: {test_f1_score:.5f}\", end=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391c927f-616b-46f8-9c7c-67dc80fdba85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_graph(graph):\n",
    "    \"\"\" \n",
    "    Helpers function that plots graph nodes and features in different colors depending on their features.\n",
    "    \n",
    "    Args: \n",
    "        graph (DataLoader sample): one graph \n",
    "    \n",
    "    \"\"\" \n",
    "    \n",
    "    node_features = graph['node_feat'].squeeze(0)\n",
    "    nodes = np.arange(node_features.size(dim=0))\n",
    "    node_ch = torch.argmax(node_features, dim=1) # extract from one hot encoding of node features\n",
    "    \n",
    "    edge_features = graph['edge_feat'].squeeze(0)\n",
    "    edge_ch = torch.argmax(edge_features, dim=1) # extract for one hot encoding of edge features\n",
    "    edge_list = graph['edge_index'].squeeze(0)\n",
    "    \n",
    "    G = convert_to_graph(graph)\n",
    "    pos=nx.spring_layout(G, seed=3113794652)\n",
    "    node_color = [\"tab:red\", \"tab:blue\", \"tab:green\", \"tab:yellow\", \"tab:orange\", \"tab:black\", \"tab:pink\"]\n",
    "    \n",
    "    for i in range(7):\n",
    "        indx1 = (node_ch==i)\n",
    "        nodelist = np.array(nodes[indx1])\n",
    "        # We add nodes\n",
    "        if nodes[indx1].shape != 0:\n",
    "            nx.draw_networkx_nodes(G, pos, nodelist=nodelist, node_color=node_color[i])\n",
    "    \n",
    "    new_edge_list = []\n",
    "    dim = len(edge_list[0])\n",
    "    for i in range(dim):\n",
    "        new_edge_list.append([edge_list[0][i], edge_list[1][i]])\n",
    "    new_edge_list = np.array(new_edge_list)\n",
    "    \n",
    "    # We add edges\n",
    "    for j in range(4):\n",
    "        indx2 = (edge_ch==j)\n",
    "        edgelist = np.array(new_edge_list[indx2])\n",
    "        if new_edge_list[indx2].shape != 0:\n",
    "            nx.draw_networkx_edges(G, pos, edgelist=edgelist, width=1, alpha=0.2, edge_color=node_color[j])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61dfb636-e021-4a10-831a-3e8ad9310564",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "graph1 = right_class[0]\n",
    "plot_graph(graph1)\n",
    "plt.figure()\n",
    "graph2 = wrong_class[0]\n",
    "plot_graph(graph2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
